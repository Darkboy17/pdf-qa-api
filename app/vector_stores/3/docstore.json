{"docstore/metadata": {"d29fc2b5-a79d-42f7-ae22-faeb559b1d1f": {"doc_hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d"}, "1f23d5d9-bee0-47c9-a55d-2a01305d8f67": {"doc_hash": "7d2a73e8c553877b332893ee140203de16b5202a2a3af72363ae4ce6c9647b80", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "49552a96-8bf5-4b69-8854-17140d368488": {"doc_hash": "141ef198dfbe38a118b969e8a802da1d6e912ec38125b39e151897ad5164d80c", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "06596a16-70d5-48ff-a8fd-dba80008d8f9": {"doc_hash": "c7e819116ea260f86de53fb356d1209cd092a0d8a5ee90236a025651c41763e2", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "7951feb3-a8cf-43c0-8075-0fb1ac912ba4": {"doc_hash": "c4fddb2386372e902fcdefcaaf7f31a0a2c8017d21536e69aa172fdede0ab87f", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "d3f97a2e-3131-4fe8-a2c7-651f03df1172": {"doc_hash": "581a2b1935d0cc4b5e9d04b990faf5ff456adb2880e49e1fdc646b6aefc31c93", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "ab823cd3-4040-4441-a24f-1a9a29f589aa": {"doc_hash": "c631256cd8f5e7c2ae2daaa773f3bbf5f215044ecd54a188656351e9ae47dec5", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "45cf733c-69c0-470a-8c79-fa810359703e": {"doc_hash": "93ba324ff153f9714e8af59a699b192aeda3fd972952b4c81aa0b3ad0816406f", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "07c3f608-22a6-446e-b666-5e03ea359526": {"doc_hash": "99953c1674a3616fb0562a297505fa8689b2bbd2790c0264cea4c99ed9d19b3d", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "33c6bf02-982f-4910-a426-54e2e05488a4": {"doc_hash": "61d0fbf6141e8bf538e51de925a25663c944a770418c1ea695f31bcc4476c2f3", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "8c6896c5-4a08-482a-99ba-28e93e228ed4": {"doc_hash": "96c662a3db778276f9e9d2b9005d86ba577dc80044cca5cb283408ac8c70a294", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "626cd07d-d4ed-4743-877d-eb7136654ca7": {"doc_hash": "89bd5ee03ab0bf4ff679f0af6936a518b415ac5d3ef085db46ce1c36e5202963", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "9cd4157f-d7b0-4480-82ae-e0320ee9117a": {"doc_hash": "232f4d01ccacefe31d943ff4ed11143c4bb3e9dbe2618b01de7759571f1115e4", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "eb6dc8b4-1032-4930-9b10-d06e1cf101e0": {"doc_hash": "1c20bbb1388a2090584c4f1641e48930c7b638139915e63d788e9adccb93d6a1", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "5606b253-28f1-427f-ae7a-b56b8fce61ac": {"doc_hash": "2f1dbd2cb66017e4a6ccd492e764f8c2f48c4074e1dc546c7e07140649ee3d9e", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "cab15ee7-e476-40e7-9b35-494889f732ee": {"doc_hash": "4fe40c6265ceeb5715275c6d471fc38afac8279d47538272079ded92151b1a41", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "1f4431ec-283e-4d4a-a00c-7c108a4ef9fb": {"doc_hash": "5083f29f5dbe85758ffc9318c5f53adf08c38a1b0d88ba2b5a282ed4ac9cd754", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "2adc2031-6d46-493a-9cd1-2a492cd385fe": {"doc_hash": "ab0aed66cd3ae83feab0d18380b160fd32bd84c04c9676b4a767a7742384550c", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "c21eceb4-6c56-4412-b88b-9ad691ca8c66": {"doc_hash": "c804af6645bf1d1dfb191a217b9276b4afa5c2cf57f4449a42655692cfb0e03e", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "35f900bb-ac69-4bf4-939b-6df36541b8b7": {"doc_hash": "180b5a36be24fc49d575ebbe850980f0cc212de525e2b0f47495f9644ef53b45", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "25192abd-6043-4c7b-8ced-a4339d7e5f56": {"doc_hash": "cc96b682f4f3b12237a1b600ef8fa1ff266b3eb5c7e5e2ce91967ccdd52608bb", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "38f079ab-a42e-40aa-b5f3-868898d1de34": {"doc_hash": "f6c56324aee93e2140f91a748d9fd93f08aefb493f2d6401c0fb40047af601d7", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "dc530a25-2cc0-4475-a051-d6214e2ba8eb": {"doc_hash": "51cccc85a68077003e1019fcf1fc0fa903cce0ce5cf85662a086bb49e94ac0dd", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "8b8d1b6a-7f76-466b-90e6-a16ae68ee9f9": {"doc_hash": "13037f3513239f3684404873890b3745ae147127284f99261f3b114369e0f99b", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "61c5d146-fcdf-426d-bfc9-47199cab8524": {"doc_hash": "7937b796ae5ec68aa7d93370987fbffd946466e26c8460887469a2f51ac2a4f8", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "1db10de4-47e8-4e09-9673-cdae92e1bef0": {"doc_hash": "4a3bce66cc2c3d2ddc8c66b657b65a06bc672ee49c103514b1300407c02548ac", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "66ad281c-f01c-4fc1-8567-ce862e25003c": {"doc_hash": "81ec8bb6e75dc5f62650e28800a377e38b136e914bad12231b8696799eee0592", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "aaeb43bc-6f0c-41c2-a6cb-395dd843e10f": {"doc_hash": "b4b2cc695b151fedc9987db1691a40da5f607fb1917c3b8869f2f7c0ddb2c09d", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "ebfed5d0-b61d-43c3-90a1-f8e1c6b04e42": {"doc_hash": "7361d3f8cb57f49821b6a0aefa47abb17967c955f8d671f4cdfeef59acaa65b3", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "fbc0d088-eba8-41a2-8fd9-a8602ded00d9": {"doc_hash": "1f0498724b640b5074b6014b2ffac2c3f4b2fd752894211afd4de09fa1d49b4c", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "c09d6d55-9a1e-4dc0-8851-4e1f269cc3fc": {"doc_hash": "64cdfd72e52c3e65521276b032cc09301044402c2352453ca42a0165b1fe6888", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "e7e43395-7990-4142-80b8-dcf895a2bbfe": {"doc_hash": "74887e3b062cf94dda4d5852021e105aa16044a1ed55089ddbe3e2fd32b42d4a", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "0c58bb55-3dd2-47d0-95a2-f7d3b9506520": {"doc_hash": "06cec37098cdbdd95520446ab57d00dd539beb7bca30e8805192188bec63de33", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "238d01c6-3743-413b-a08e-cda027116527": {"doc_hash": "cf69c375402c20e860818b9b174a562d45ff66be518f6b36c40ea6e4eeab60e0", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "824ca562-fd48-4ed8-8b0f-8ac15f8466ab": {"doc_hash": "e68dfc01daf445e6d22e188c62418048c11f9d4d0aa2df76e75640dfcb0cf6da", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "1b7e121c-8beb-4140-9196-4626e73d5365": {"doc_hash": "b0aaaf4dfd345e363cd0ca61820b325c379255074150c3f562826b1a8c486c2b", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "309cea40-21a3-4a5a-b96a-0379e499eafe": {"doc_hash": "54e6fcaf7756bbd0a9a8d5acbdc4178e731df80e54b25955dee47705e5b49ea4", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}, "724c04e8-211f-404f-a53d-3e2eb512d990": {"doc_hash": "7637b34d06466fae5c1eb9c27aa833f19d3738c852c863ab906d87c8566e0435", "ref_doc_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f"}}, "docstore/data": {"1f23d5d9-bee0-47c9-a55d-2a01305d8f67": {"__data__": {"id_": "1f23d5d9-bee0-47c9-a55d-2a01305d8f67", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "49552a96-8bf5-4b69-8854-17140d368488", "node_type": "1", "metadata": {}, "hash": "141ef198dfbe38a118b969e8a802da1d6e912ec38125b39e151897ad5164d80c", "class_name": "RelatedNodeInfo"}}, "text": "AI FOR GAMES\n\nAI FOR EVERYTHING\nArtificial intelligence (AI) is all around us. From driverless cars to \ngame-winning computers to fraud protection, AI is already involved \nin many aspects of life, and its impact will only continue to grow \nin the future. Many of the world\u2019s most valuable companies are \ninvesting heavily in AI research and development, and not a day goes \nby without news of cutting-edge breakthroughs in AI and robotics.\nThe AI for Everything series will explore the role of AI in contemporary \nlife, from cars and aircraft to medicine, education, fashion, and \nbeyond. Concise and accessible, each book is written by an expert \nin the field and will bring the study and reality of AI to a broad \nreadership including interested professionals, students, researchers, \nand lay readers.\nAI for Immunology\nLouis J. Catania\nAI for Cars\nHanky Sjafrie & Josep Aulinas\nAI for Digital Warfare\nNiklas Hageback & Daniel Hedblom\nAI for Art\nNiklas Hageback & Daniel Hedblom\nAI for Creativity\nNiklas Hageback\nAI for Death and Dying\nMaggi Savin-Baden\nAI for Radiology\nOge Marques\nAI for Games\nIan Millington\nAI for School Teachers\nRose Luckin & Karine George\nAI for Learners\nCarmel Kent, Benedict du Boulay & Rose \nLuckin\nAI for Social Justice\nAlan Dix and Clara Crivellaro\nFor more information about this series please visit:  \n \nhttps://www.routledge.com/AI-for-Everything/book-series/AIFE\n\nAI FOR GAMES\nIAN MILLINGTON\n\nFirst Edition published 2022\nby CRC Press\n6000 Broken Sound Parkway NW, Suite 300, Boca Raton, FL 33487-2742\nand by CRC Press\n2 Park Square, Milton Park, Abingdon, Oxon, OX14 4RN\n\u00a9 2022 Ian Millington\nCRC Press is an imprint of Taylor & Francis Group, LLC\nReasonable efforts have been made to publish reliable data and information, but the \nauthor and publisher cannot assume responsibility for the validity of all materials or \nthe consequences of their use. The authors and publishers have attempted to trace \nthe \u00adcopyright holders of all material reproduced in this publication and apologize to \ncopyright holders if permission to publish in this form has not been obtained. If any \ncopyright material has not been acknowledged please write and let us know so we may \nrectify in any future reprint.\nExcept as permitted under U.S. Copyright Law, no part of this book may be reprinted, \nreproduced, transmitted, or utilized in any form by any electronic, mechanical, or other \nmeans, now known or hereafter invented, including photocopying, microfilming, and \nrecording, or in any information storage or retrieval system, without written permission \nfrom the publishers.\nFor permission to photocopy or use material electronically from this work, access  \nwww.copyright.com or contact the Copyright Clearance Center, Inc. (CCC), 222 \n\u00adRosewood Drive, Danvers, MA 01923, 978-750-8400. For works that are not available \non CCC please contact mpkbookspermissions@tandf.co.uk\nTrademark notice: Product or corporate names may be trademarks or registered trademarks \nand are used only for identification and explanation without intent to infringe.\nLibrary of Congress Cataloging\u2011in\u2011Publication Data\nNames: Millington, Ian, author. \nTitle: AI for games / Ian Millington. \nDescription: Fourth edition. | Boca Raton : CRC Press, 2022. | \nIncludes bibliographical references and index. \nIdentifiers: LCCN 2021027654 | ISBN 9780367643447 (hardback) | \nISBN 9780367643430 (paperback) | ISBN 9781003124047 (ebook) \nSubjects: LCSH: Computer games\u2014Programming. | Artificial intelligence. | \nComputer animation. \nClassification: LCC QA76.76.C672 M549 2022 | DDC 794.8/1525\u2014dc23 \nLC record available at https://lccn.loc.gov/2021027654\nISBN: 978-0-367-64344-7 (hbk)\nISBN: 978-0-367-64343-0 (pbk)\nISBN: 978-1-003-12404-7 (ebk)\nDOI: 10.1201/9781003124047\nTypeset in Joanna\nby codeMantra\n\nAuthor \nvii\nIntroduction \n1\n1 \nWhat Is AI?", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 3839, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "49552a96-8bf5-4b69-8854-17140d368488": {"__data__": {"id_": "49552a96-8bf5-4b69-8854-17140d368488", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1f23d5d9-bee0-47c9-a55d-2a01305d8f67", "node_type": "1", "metadata": {}, "hash": "7d2a73e8c553877b332893ee140203de16b5202a2a3af72363ae4ce6c9647b80", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "06596a16-70d5-48ff-a8fd-dba80008d8f9", "node_type": "1", "metadata": {}, "hash": "c7e819116ea260f86de53fb356d1209cd092a0d8a5ee90236a025651c41763e2", "class_name": "RelatedNodeInfo"}}, "text": "| Artificial intelligence. | \nComputer animation. \nClassification: LCC QA76.76.C672 M549 2022 | DDC 794.8/1525\u2014dc23 \nLC record available at https://lccn.loc.gov/2021027654\nISBN: 978-0-367-64344-7 (hbk)\nISBN: 978-0-367-64343-0 (pbk)\nISBN: 978-1-003-12404-7 (ebk)\nDOI: 10.1201/9781003124047\nTypeset in Joanna\nby codeMantra\n\nAuthor \nvii\nIntroduction \n1\n1 \nWhat Is AI? \n3\n2 \nModel of Game AI \n11\n3 \nAlgorithms and Data Structures \n17\n4 \nGame AI \n21\n5 \nTechniques \n47\n6 \nSupporting Technologies \n65\nIndex \n71\nCONTENTS\n\n\nIan Millington is a British developer and author of books and courses \non software development, particularly in the fields of artificial intelli-\ngence, decision support, and game physics engine development. Also \nan AJAX technology pioneer, Millington is attributed with creating a \nmodel of distributed power for management of a creative game with \na troupe system style of play.\nAUTHOR\n\n\nDOI: 10.1201/9781003124047-1\nINTRODUCTION\nGame development lives in its own technical world. It has its own \nidioms, skills, and challenges. That\u2019s one of the reasons games are so \nmuch fun to work on. Each game has its own rules, its own aesthetic, \nand its own trade-offs, and the hardware it will run on keeps chang-\ning. There\u2019s a reasonably good chance you will be the first person to \nmeet and beat a new programming challenge.\nDespite numerous efforts to standardize game development in \nline with the rest of the software industry (efforts that go back at \nleast 25 years), the style of programming in a game is still rather \nunique. There is a focus on speed, but it differs from real-time pro-\ngramming for embedded or control applications. There is a focus \non clever algorithms, but it doesn\u2019t share the same rigor as database \nserver engineering. It draws techniques from a huge range of differ-\nent sources, but almost without exception modifies them beyond \nresemblance. And, to add an extra layer of intrigue, developers make \ntheir modifications in different ways, often under extreme time pres-\nsure, and tailored entirely to the game at hand, leaving algorithms \nunrecognizable from studio to studio or project to project.\nAs exciting and challenging as this may be, it makes it difficult \nfor new developers to get the information they need. Twenty years \nago, it was almost impossible to get hold of information about tech-\nniques and algorithms that real developers used in their games. There \nwas an atmosphere of secrecy, even alchemy, about the coding tech-\nniques in top studios. Then came the Internet and an ever-growing \nrange of websites, along with books, conferences, and periodicals. \nIt is now easier than ever to teach yourself new techniques in game \ndevelopment.\n\n2\u2002 INTRODUCTION\nThis book is designed to help you understand one element of \ngame development: artificial intelligence (AI). There have been many \narticles published about different aspects of game AI and websites \non particular techniques, compilations in book form, some intro-\nductory texts, and plenty of lectures at development conferences. A \nmuch more detailed discussion of the topics presented here can be \nfound in my book AI for Games, Third Edition (CRC Press, 2019).\n\nDOI: 10.1201/9781003124047-2\n1\nWHAT IS AI?\nArtificial intelligence is about making computers able to perform the \nthinking tasks that humans and animals are capable of.\nWe can program computers to have superhuman abilities in solv-\ning many problems: arithmetic, sorting, searching, and so on. Some \nof these problems were originally considered AI problems, but as \nthey have been solved in more and more comprehensive ways, they \nhave slipped out of the domain of AI developers.\nBut there are many things that computers aren\u2019t good at which we \nfind trivial: recognizing familiar faces, speaking our own language, \ndeciding what to do next, and being creative. These are the domains \nof AI: trying to work out what kinds of algorithms are needed to \ndisplay these properties.\nOften the dividing line between AI and not-AI is merely difficulty: \nthings we can\u2019t do require AI, things we can are tricks and math.", "mimetype": "text/plain", "start_char_idx": 3475, "end_char_idx": 7574, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "06596a16-70d5-48ff-a8fd-dba80008d8f9": {"__data__": {"id_": "06596a16-70d5-48ff-a8fd-dba80008d8f9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49552a96-8bf5-4b69-8854-17140d368488", "node_type": "1", "metadata": {}, "hash": "141ef198dfbe38a118b969e8a802da1d6e912ec38125b39e151897ad5164d80c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7951feb3-a8cf-43c0-8075-0fb1ac912ba4", "node_type": "1", "metadata": {}, "hash": "c4fddb2386372e902fcdefcaaf7f31a0a2c8017d21536e69aa172fdede0ab87f", "class_name": "RelatedNodeInfo"}}, "text": "Artificial intelligence is about making computers able to perform the \nthinking tasks that humans and animals are capable of.\nWe can program computers to have superhuman abilities in solv-\ning many problems: arithmetic, sorting, searching, and so on. Some \nof these problems were originally considered AI problems, but as \nthey have been solved in more and more comprehensive ways, they \nhave slipped out of the domain of AI developers.\nBut there are many things that computers aren\u2019t good at which we \nfind trivial: recognizing familiar faces, speaking our own language, \ndeciding what to do next, and being creative. These are the domains \nof AI: trying to work out what kinds of algorithms are needed to \ndisplay these properties.\nOften the dividing line between AI and not-AI is merely difficulty: \nthings we can\u2019t do require AI, things we can are tricks and math. It is \ntempting to get into a discussion of what is \u201creal\u201d AI, to try defining \n\u201cintelligence,\u201d \u201cconsciousness,\u201d or \u201cthought.\u201d In my experience, it \nis an impossible task, largely irrelevant to the business of making \ngames.\nIn academia, some AI researchers are motivated by those phil-\nosophical questions: understanding the nature of thought and the \nnature of intelligence and building software to model how thinking \nmight work. Others are motivated by psychology: understanding \nthe mechanics of the human brain and mental processes. And yet \n\n4\u2002 \u2009WHAT IS AI?\nothers are motivated by engineering: building algorithms to per-\nform human-like tasks. This threefold distinction is at the heart of \nacademic AI, and the different concerns are responsible for different \nsubfields of the subject.\nAs games developers, we are practical folks, interested in only the \nengineering side. We build algorithms that make game characters \nappear human or animal-like. Developers have always drawn from \nacademic research, where that research helps them get the job done, \nand ignored the rest.\nIt is worth taking a quick overview of the AI work done in aca-\ndemia to get a sense of what exists in the subject and what might be \nworth plagiarizing.\nACADEMIC AI\nTo tell the story, I will divide academic AI into three periods: the early \ndays, the symbolic era, and the natural computing and statistical era. \nThis is a gross oversimplification, of course, and they all overlap to \nsome extent, but I find it a useful distinction.\nTHE EARLY DAYS\nThe early days include the time before computers, where philoso-\nphy of mind occasionally made forays into AI with such questions \nas: \u201cWhat produces thought?\u201d \u201cCould you give life to an inanimate \nobject?\u201d \u201cWhat is the difference between a cadaver and the human it \npreviously was?\u201d Tangential to this was the popular taste in automata, \nmechanical robots, from the 18th century onward. Intricate clock-\nwork models were created that displayed the kind of animated, ani-\nmal or human-like behaviors that we now employ game artists to \ncreate in a modeling package.\nIn the war effort of the 1940s, the need to break enemy codes and \nto perform the calculations required for atomic warfare motivated \nthe development of the first programmable computers. Given that \nthese machines were being used to perform calculations that would \n\nWHAT IS AI?\u2002 \u20095\notherwise be done by a person, it was natural for programmers to \nbe interested in AI. Several computing pioneers (such as Turing, von \nNeumann, and Shannon) were also pioneers in early AI.\nTHE SYMBOLIC ERA\nFrom the late 1950s through to the early 1980s, the main thrust of \nAI research was \u201csymbolic\u201d systems. A symbolic system is one in \nwhich the algorithm is divided into two components: a set of knowl-\nedge (represented as symbols such as words, numbers, sentences, or \npictures) and a reasoning algorithm that manipulates those symbols \nto create new combinations that hopefully represent problem solu-\ntions or new knowledge.\nAn expert system, one of the purest expressions of this approach, \nis among the most famous AI techniques. If today all the AI head-\nlines talk about \u201cdeep learning,\u201d in the 1980s, they name dropped \n\u201cexpert systems.\u201d An expert system has a large database of knowl-\nedge, and it applies a collection of rules to draw conclusions or to \ndiscover new things. Other symbolic approaches applicable to games \ninclude blackboard architectures, pathfinding, decision trees, and \nstate machines.\nA common feature of symbolic systems is a trade-off: When solv-\ning a problem the more knowledge you have, the less work you need \nto do in reasoning. Often, reasoning algorithms consist of searching: \ntrying different possibilities to get the best result.", "mimetype": "text/plain", "start_char_idx": 6706, "end_char_idx": 11338, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7951feb3-a8cf-43c0-8075-0fb1ac912ba4": {"__data__": {"id_": "7951feb3-a8cf-43c0-8075-0fb1ac912ba4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "06596a16-70d5-48ff-a8fd-dba80008d8f9", "node_type": "1", "metadata": {}, "hash": "c7e819116ea260f86de53fb356d1209cd092a0d8a5ee90236a025651c41763e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d3f97a2e-3131-4fe8-a2c7-651f03df1172", "node_type": "1", "metadata": {}, "hash": "581a2b1935d0cc4b5e9d04b990faf5ff456adb2880e49e1fdc646b6aefc31c93", "class_name": "RelatedNodeInfo"}}, "text": "An expert system, one of the purest expressions of this approach, \nis among the most famous AI techniques. If today all the AI head-\nlines talk about \u201cdeep learning,\u201d in the 1980s, they name dropped \n\u201cexpert systems.\u201d An expert system has a large database of knowl-\nedge, and it applies a collection of rules to draw conclusions or to \ndiscover new things. Other symbolic approaches applicable to games \ninclude blackboard architectures, pathfinding, decision trees, and \nstate machines.\nA common feature of symbolic systems is a trade-off: When solv-\ning a problem the more knowledge you have, the less work you need \nto do in reasoning. Often, reasoning algorithms consist of searching: \ntrying different possibilities to get the best result. This leads us to the \ngolden rule of AI:\nSearch and knowledge are intrinsically linked. The more knowl-\nedge you have, the less searching for an answer you need; the \nmore search you can do (i.e., the faster you can search), the less \nknowledge you need.\nSome have suggested that knowledge-infused search (known as \n\u201cheuristic search\u201d) is the way all intelligent behavior arises. Unfor-\ntunately, despite having several solid and important features, this \n\n6\u2002 \u2009WHAT IS AI?\ntheory has largely been discredited as an account of all intelligence. \nNevertheless, many people with a recent education in AI are not \naware that, as an engineering trade-off, knowledge versus search is \nunavoidable. At a practical level, AI engineers have always known it.\nTHE NATURAL COMPUTING/STATISTICAL ERA\nThrough the 1980s and into the early 1990s, there was an increas-\ning frustration with symbolic approaches. The frustration came from \nvarious directions.\nFrom an engineering point of view, the early successes on simple \nproblems didn\u2019t seem to scale to more difficult problems. For exam-\nple, it seemed easy to develop AI that understood (or appeared to \nunderstand) simple sentences, but developing an understanding of \na full human language seemed no nearer. This was compounded by \nhype: When AI touted as \u201cthe next big thing\u201d failed to live up to its \nbilling, confidence in the whole sector crashed.\nThere was also an influential philosophical argument that sym-\nbolic approaches weren\u2019t biologically plausible. You can\u2019t understand \nhow a human being plans a route by using a symbolic route-plan-\nning algorithm any more than you can understand how human mus-\ncles work by studying a forklift truck.\nThe effect was a move toward natural computing: techniques \ninspired by biology or other natural systems. These techniques \ninclude neural networks, genetic algorithms, and simulated anneal-\ning. Many natural computing techniques have been around for a long \ntime.\nBut in the 1980s through to the early 2000s, they received the \nbulk of the research effort. When I began my PhD in artificial intelli-\ngence in the 1990s, it was difficult to find research places in Expert \nSystems, for example. I studied genetic algorithms; most of my peers \nwere working on neural networks.\nDespite its origin as a correlate to biology, AI research heav-\nily applied mathematics, particularly probability and statistics, to \n\nWHAT IS AI?\u2002 \u20097\nunderstanding and optimizing natural computing techniques. The \nability to handle all the uncertainty and messiness of real-world \ndata, in contrast to the clean and rigid boundaries of the symbolic \napproaches, led to the development of a wide range of other prob-\nabilistic techniques, such as Bayes nets, support-vector machines \n(SVMs), and Gaussian processes.\nThe biggest change in AI in the last decade has not come from a \nbreakthrough in academia. We are living in a time when AI is again \nback in the newspapers: self-driving cars, deep fakes, world cham-\npion Go programs, and home virtual assistants. This is the era of deep \nlearning. Though many academic innovations are used, these systems \nare still fundamentally powered by neural networks, now made prac-\ntical by the increase in computing power.\nENGINEERING\nThough newspaper headlines and high-profile applications have \nflourished in the last 5 years, AI has been a key technology relevant \nto solving real-world problems for decades. Navigation systems in \ncars, job scheduling in factories, voice recognition and dictation, \nand large-scale search are all more than 20 years old. Google\u2019s search \ntechnology, for example, has long been underpinned by AI.\nWhen something is hot, it is tempting to assume it is the only \nthing that matters. When natural computing techniques took center \nstage, there was a tendency to assume that symbolic approaches were \ndead.", "mimetype": "text/plain", "start_char_idx": 10594, "end_char_idx": 15191, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d3f97a2e-3131-4fe8-a2c7-651f03df1172": {"__data__": {"id_": "d3f97a2e-3131-4fe8-a2c7-651f03df1172", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7951feb3-a8cf-43c0-8075-0fb1ac912ba4", "node_type": "1", "metadata": {}, "hash": "c4fddb2386372e902fcdefcaaf7f31a0a2c8017d21536e69aa172fdede0ab87f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ab823cd3-4040-4441-a24f-1a9a29f589aa", "node_type": "1", "metadata": {}, "hash": "c631256cd8f5e7c2ae2daaa773f3bbf5f215044ecd54a188656351e9ae47dec5", "class_name": "RelatedNodeInfo"}}, "text": "This is the era of deep \nlearning. Though many academic innovations are used, these systems \nare still fundamentally powered by neural networks, now made prac-\ntical by the increase in computing power.\nENGINEERING\nThough newspaper headlines and high-profile applications have \nflourished in the last 5 years, AI has been a key technology relevant \nto solving real-world problems for decades. Navigation systems in \ncars, job scheduling in factories, voice recognition and dictation, \nand large-scale search are all more than 20 years old. Google\u2019s search \ntechnology, for example, has long been underpinned by AI.\nWhen something is hot, it is tempting to assume it is the only \nthing that matters. When natural computing techniques took center \nstage, there was a tendency to assume that symbolic approaches were \ndead. Similarly, with talk of deep learning everywhere, you might be \nforgiven for thinking that is what should be used.\nBut we always come back to the same trade-off: search vs knowl-\nedge. Deep learning is the ultimate in the compute-intensive search; \nAlphaGo Zero (the third iteration of the AlphaGo software) was given \nvery minimal knowledge of the rules of the game, but extraordinary \namounts of processing time to try different strategies and learn the \nbest. On the other hand, a character that needs to use a health pack \nwhen injured can be told that explicitly:\n\n8\u2002 \u2009WHAT IS AI?\nIF injured THEN use health pack\nNo search required.\nThe only way any algorithm can outperform another is either to \nconsume more processing power (more search), or to be optimized \ntoward a specific set of problems (more knowledge of the problem).\nIn practice, engineers work from both sides. A voice recognition \nprogram, for example, converts the input signals using known for-\nmulae into a format where the neural network can decode it. The \nresults are then fed through a series of symbolic algorithms that look \nat words from a dictionary and the way words are combined in the \nlanguage. A statistical algorithm optimizing the order of a produc-\ntion line will have the rules about production encoded into its struc-\nture, so it can\u2019t possibly suggest an illegal timetable: The knowledge \nis used to reduce the amount of search required.\nUnfortunately, games are usually designed to run on consumer \nhardware. And while AI is important, graphics have always taken \nthe majority of the processing power. This seems in no danger of \nchanging. For AI designed to run on the device during the game, low \ncomputation/high knowledge approaches are often the clear win-\nners. And these are very often symbolic: approaches pioneered in \nacademia in the 1970s and 1980s.\nGAME AI\nPac-Man was the first game many people remember playing with \nfledgling AI. Up to that point, there had been Pong clones with oppo-\nnent-controlled bats (following the ball up and down) and countless \nshooters in the Space Invaders mold. But Pac-Man had definite enemy \ncharacters that seemed to conspire against you, moved around the \nlevel just as you did, and made life tough.\nPac-Man relied on a very simple AI technique: a state machine. Each \nof the four monsters (later called ghosts after a disastrously flickering \nport to the Atari 2600) occupied one of three states: chasing, scatter-\ning (heading for the corners at specific time intervals), and fright-\nened (when Pac-Man eats a power-up). For each state, they choose a \n\nWHAT IS AI?\u2002 \u20099\ntile as their target and turn toward it at each junction. In chase mode, \neach ghost chooses the target according to a slightly different hard-\ncoded rule, giving them their personalities.\nGame AI didn\u2019t change much until the mid-1990s. Most comput-\ner-controlled characters prior to then were about as sophisticated as \na Pac-Man ghost.\nTake a classic like Golden Axe eight years later. Enemy characters \nstood still (or walked back and forward a short distance) until the \nplayer got close to them, whereupon they homed in on the player. \nGolden Axe had a neat innovation with enemies that would enter a \nrunning state to rush past the player and then switch back to homing \nmode, attacking from behind. Surrounding the player looks impres-\nsive, but the underlying AI is no more complex than Pac-Man.\nIn the mid-1990s, AI began to be a selling point for games. Games \nlike Beneath a Steel Sky even mentioned AI on the back of the box. Unfor-\ntunately, its much-hyped \u201cVirtual Theater\u201d AI system simply allowed \ncharacters to walk backward and forward through the game\u2014hardly \na real advancement.", "mimetype": "text/plain", "start_char_idx": 14372, "end_char_idx": 18902, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ab823cd3-4040-4441-a24f-1a9a29f589aa": {"__data__": {"id_": "ab823cd3-4040-4441-a24f-1a9a29f589aa", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d3f97a2e-3131-4fe8-a2c7-651f03df1172", "node_type": "1", "metadata": {}, "hash": "581a2b1935d0cc4b5e9d04b990faf5ff456adb2880e49e1fdc646b6aefc31c93", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "45cf733c-69c0-470a-8c79-fa810359703e", "node_type": "1", "metadata": {}, "hash": "93ba324ff153f9714e8af59a699b192aeda3fd972952b4c81aa0b3ad0816406f", "class_name": "RelatedNodeInfo"}}, "text": "Most comput-\ner-controlled characters prior to then were about as sophisticated as \na Pac-Man ghost.\nTake a classic like Golden Axe eight years later. Enemy characters \nstood still (or walked back and forward a short distance) until the \nplayer got close to them, whereupon they homed in on the player. \nGolden Axe had a neat innovation with enemies that would enter a \nrunning state to rush past the player and then switch back to homing \nmode, attacking from behind. Surrounding the player looks impres-\nsive, but the underlying AI is no more complex than Pac-Man.\nIn the mid-1990s, AI began to be a selling point for games. Games \nlike Beneath a Steel Sky even mentioned AI on the back of the box. Unfor-\ntunately, its much-hyped \u201cVirtual Theater\u201d AI system simply allowed \ncharacters to walk backward and forward through the game\u2014hardly \na real advancement.\nGoldeneye 007 probably did the most to show gamers what AI could \ndo to improve gameplay. Still relying on characters with a small num-\nber of well-defined states, Goldeneye added a sense simulation system: \nCharacters could see their colleagues and would notice if they were \nkilled. Sense simulation was the topic of the moment, with Thief: The \nDark Project and Metal Gear Solid basing their whole game design on the \ntechnique.\nIn the mid-1990s, real-time strategy (RTS) games also were \nbeginning to take off. World of WarCraft was one of the first times \npathfinding was widely noticed in action (though it had been used \nseveral times before). AI researchers were working with emotional \nmodels of soldiers in a military battlefield simulation in 1998 when \nthey saw Warhammer: Dark Omen doing the same thing. It was also one \nof the first times people saw robust formation motion in action.\nHalo introduced decision trees, now a standard method for char-\nacters to decide what to do. F.E.A.R. used goal-oriented action plan-\nning (GOAP) for the same purpose. With the success of AlphaGo, deep \n\n10\u2002 \u2009WHAT IS AI?\nlearning has become a hot topic, though it is still only practicable \noffline.\nSome games are designed around the AI. Creatures did this in 1997, \nbut games like The Sims and its sequels, or Black & White have carried \non the torch. Creatures still has one of the most complex AI systems \nseen in a game, with a simulated hormone system and a neural net-\nwork-based brain for each creature.\nGames like Half-Life and The Last of Us use AI-controlled characters \nto collaborate with the player, meaning they are on screen for much \nlonger, and any faults are much more noticeable.\nFirst-person shooters and RTS games have been subjected to \nsignificant academic research (there is an annual competition for \nStarCraft AI, for example). RTS games incorporate AI techniques used \nin military simulation (to the extent that Full Spectrum Warrior started \nlife as a military training simulator).\nSports games and driving games in particular have their own AI \nchallenges, some of which remain largely unsolved (dynamically cal-\nculating the fastest way around a race track, for example, would also \nbe helpful to motorsport teams), while role-playing games (RPGs) \nwith complex character interactions still implemented as conversa-\ntion trees feel overdue for something better (interesting and sophis-\nticated conversation AI has been implemented in games such as Fa\u00e7ade \nand Blood and Laurels, the one released game using the short-lived Versu \ngame engine).\nWe have come a long way, certainly. But, though we have a mas-\nsive diversity of AI in games, many genres are still using the simple \nAI of 1979 because that\u2019s all they need.\nThe AI in most games addresses three basic needs: the ability to \nmove characters, the ability to make decisions about where to move, \nand the ability to think tactically or strategically. Even though we \nhave a broad range of approaches, they all fulfill the same three basic \nrequirements.\n\nDOI: 10.1201/9781003124047-3\n2\nMODEL OF GAME AI\nThere is a vast zoo of algorithms and techniques in game AI. It would \nbe easy to get lost, so it\u2019s important to understand how the bits fit \ntogether. To help, I\u2019ve used a consistent structure to contextualize the \nAI used in a game. This isn\u2019t the only possible model, and it isn\u2019t the \nonly model that would benefit from the techniques in this book.\nFigure 2.1 illustrates this model. It splits the AI task into three sec-\ntions: movement, decision-making, and strategy.", "mimetype": "text/plain", "start_char_idx": 18041, "end_char_idx": 22466, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "45cf733c-69c0-470a-8c79-fa810359703e": {"__data__": {"id_": "45cf733c-69c0-470a-8c79-fa810359703e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab823cd3-4040-4441-a24f-1a9a29f589aa", "node_type": "1", "metadata": {}, "hash": "c631256cd8f5e7c2ae2daaa773f3bbf5f215044ecd54a188656351e9ae47dec5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "07c3f608-22a6-446e-b666-5e03ea359526", "node_type": "1", "metadata": {}, "hash": "99953c1674a3616fb0562a297505fa8689b2bbd2790c0264cea4c99ed9d19b3d", "class_name": "RelatedNodeInfo"}}, "text": "The AI in most games addresses three basic needs: the ability to \nmove characters, the ability to make decisions about where to move, \nand the ability to think tactically or strategically. Even though we \nhave a broad range of approaches, they all fulfill the same three basic \nrequirements.\n\nDOI: 10.1201/9781003124047-3\n2\nMODEL OF GAME AI\nThere is a vast zoo of algorithms and techniques in game AI. It would \nbe easy to get lost, so it\u2019s important to understand how the bits fit \ntogether. To help, I\u2019ve used a consistent structure to contextualize the \nAI used in a game. This isn\u2019t the only possible model, and it isn\u2019t the \nonly model that would benefit from the techniques in this book.\nFigure 2.1 illustrates this model. It splits the AI task into three sec-\ntions: movement, decision-making, and strategy. The first two sec-\ntions contain algorithms that work on a character-by-character basis, \nand the last section operates on a team or side. Around these three AI \nelements is a whole set of additional infrastructure.\nNot all game applications require all levels of AI. Board games like \nChess or Risk require only the strategy level; the characters in the \ngame (if they can even be called that) don\u2019t make their own deci-\nsions and don\u2019t need to worry about how to move.\nOn the other hand, there is no strategy at all in many games. Non-\nplayer characters in a platform game, such as Hollow Knight or Super \nMario Bros., are purely reactive, making their own simple decisions \nand acting on them. There is no coordination that makes sure the \nenemy characters do the best job of thwarting the player.\n\n12\u2002 \u2009MODEL OF GAME AI\nMOVEMENT\nMovement refers to algorithms that turn decisions into some kind of \nmotion. When an enemy character without a projectile attack needs \nto attack the player in Super Mario Sunshine, it first heads directly for the \nplayer. When it is close enough, it can actually do the attacking. The \ndecision to attack is carried out by a set of movement algorithms that \nhome in on the player\u2019s location. Only then can the attack animation \nbe played and the player\u2019s health be depleted.\nMovement algorithms can be more complex than simply hom-\ning in. A character may need to avoid obstacles on the way or even \nwork their way through a series of rooms. A guard in some levels \nof Splinter Cell will respond to the appearance of the player by raising \nan alarm. This may require navigating to the nearest wall-mounted \nalarm point, which can be a long distance away and may involve \ncomplex navigation around obstacles or through corridors.\nLots of actions are carried out using animation directly. If a Sim, \nin The Sims, is sitting by the table with food in front of her and wants \nFigure 2.1 The AI model.\n\nMODEL OF GAME AI\u2002 \u200913\nto carry out an eating action, then the eating animation is simply \nplayed. Once the AI has decided that the character should eat, no \nmore AI is needed (the animation technology used is not covered in \nthis book). If the same character is by the back door when she wants \nto eat, however, movement AI needs to guide her to the chair (or to \nsome other nearby source of food).\nDECISION-MAKING\nDecision-making involves a character working out what to do next. \nTypically, each character has a range of different behaviors that they \ncould choose to perform: attacking, standing still, hiding, exploring, \npatrolling, and so on. The decision-making system needs to work out \nwhich of these behaviors is the most appropriate at each moment of \nthe game. The chosen behavior can then be executed using move-\nment AI and animation technology.\nAt its simplest, a character may have very simple rules for select-\ning a behavior. The farm animals in various levels of the Legend of Zelda \ngames will stand still unless the player gets too close, whereupon \nthey will move away a small distance.\nAt the other extreme, enemies in Half-Life 2 display complex deci-\nsion-making, where they will try a number of different strategies \nto reach the player: chaining together intermediate actions such as \nthrowing grenades and laying down suppression fire in order to \nachieve their goals.\nSome decisions may require movement AI to carry them out. A \nmelee (hand-to-hand) attack will require the character to get close to \nits victim. In combat-heavy games such as Dark Souls, decision-making \nmoves the character toward their target and also determines which \nattack, and thus which animation, is performed.", "mimetype": "text/plain", "start_char_idx": 21652, "end_char_idx": 26114, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "07c3f608-22a6-446e-b666-5e03ea359526": {"__data__": {"id_": "07c3f608-22a6-446e-b666-5e03ea359526", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "45cf733c-69c0-470a-8c79-fa810359703e", "node_type": "1", "metadata": {}, "hash": "93ba324ff153f9714e8af59a699b192aeda3fd972952b4c81aa0b3ad0816406f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "33c6bf02-982f-4910-a426-54e2e05488a4", "node_type": "1", "metadata": {}, "hash": "61d0fbf6141e8bf538e51de925a25663c944a770418c1ea695f31bcc4476c2f3", "class_name": "RelatedNodeInfo"}}, "text": "The chosen behavior can then be executed using move-\nment AI and animation technology.\nAt its simplest, a character may have very simple rules for select-\ning a behavior. The farm animals in various levels of the Legend of Zelda \ngames will stand still unless the player gets too close, whereupon \nthey will move away a small distance.\nAt the other extreme, enemies in Half-Life 2 display complex deci-\nsion-making, where they will try a number of different strategies \nto reach the player: chaining together intermediate actions such as \nthrowing grenades and laying down suppression fire in order to \nachieve their goals.\nSome decisions may require movement AI to carry them out. A \nmelee (hand-to-hand) attack will require the character to get close to \nits victim. In combat-heavy games such as Dark Souls, decision-making \nmoves the character toward their target and also determines which \nattack, and thus which animation, is performed. In other games, once \nthe decision is made, a predetermined animation is played without any \nadditional movement (a Sim eating, for example) or the state of the \ngame is directly modified without any kind of visual feedback (when a \ncountry AI in Sid Meier\u2019s Civilization VI elects to research a new technology, \nfor example, it simply happens with no visual feedback to the player).\n\n14\u2002 \u2009MODEL OF GAME AI\nSTRATEGY\nYou can go a long way with movement AI and decision-making AI, \nand most action-based three-dimensional (3D) games use only these \ntwo elements. But to coordinate a whole team, some strategic AI is \nrequired.\nIn the context of this book, strategy refers to an overall approach \nused by a group of characters. In this category are AI algorithms \nthat don\u2019t control just one character, but influence the behavior of a \nwhole set of characters. Each character in the group may (and usually \nwill) have their own decision-making and movement algorithms, \nbut overall, their decision-making will be influenced by a group \nstrategy.\nIn the original Half-Life, enemies worked as a team to surround \nand eliminate the player. One would often rush past the player to take \nup a flanking position. This has been followed in more recent games, \nsuch as the evolving AI engine in the Medal of Honor franchise. Over \ntime, we have seen increasing sophistication in the kinds of strategic \nactions that a team of enemies can carry out.\nINFRASTRUCTURE\nAI algorithms on their own are only half of the story, however. In \norder to actually build AI for a game, we\u2019ll need a whole set of addi-\ntional infrastructure. The movement requests need to be turned into \naction in the game by using either animation or, increasingly, physics \nsimulation.\nSimilarly, the AI needs information from the game to make sen-\nsible decisions. This is sometimes called \u201cperception\u201d (especially in \nacademic AI): working out what information the character knows. In \npractice, it is much broader than just simulating what each character \ncan see or hear, but includes all interfaces between the game world \nand the AI. This world interfacing is often a significant proportion of \nthe work done by an AI programmer, and in my experience, it is a \nlarge proportion of the AI debugging effort.\n\nMODEL OF GAME AI\u2002 \u200915\nFinally, the whole AI system needs to be managed so that it uses \nthe right amount of processor time and memory. While some kind \nof execution management typically exists for each area of the game \n(level of detail algorithms for rendering, for example), managing the \nAI raises a whole set of techniques and algorithms of its own.\nEach of these components may be thought of as being out of the \nremit of the AI developer. Sometimes they are (in particular, the ani-\nmation system is often part of the graphics engine, or increasingly \nhas its own dedicated programmers), but they are so crucial to get-\nting the AI working that they can\u2019t be avoided altogether.\nAGENT-BASED AI\nI don\u2019t use the term \u201cagents\u201d very much in this book, even though \nthe model I\u2019ve described is an agent-based model.\nIn this context, agent-based AI is about producing autonomous \ncharacters that take in information from the game data, determine what \nactions to take based on the information, and carry out those actions.\nIt can be seen as bottom-up design: You start by working out how \neach character will behave and by implementing the AI needed to \nsupport that. The overall behavior of the game is then a function of \nhow the individual character behaviors work together. The first two \nelements of the AI model we\u2019ll use, movement and decision-making, \nmake up the AI for an agent in the game.", "mimetype": "text/plain", "start_char_idx": 25172, "end_char_idx": 29787, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "33c6bf02-982f-4910-a426-54e2e05488a4": {"__data__": {"id_": "33c6bf02-982f-4910-a426-54e2e05488a4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07c3f608-22a6-446e-b666-5e03ea359526", "node_type": "1", "metadata": {}, "hash": "99953c1674a3616fb0562a297505fa8689b2bbd2790c0264cea4c99ed9d19b3d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c6896c5-4a08-482a-99ba-28e93e228ed4", "node_type": "1", "metadata": {}, "hash": "96c662a3db778276f9e9d2b9005d86ba577dc80044cca5cb283408ac8c70a294", "class_name": "RelatedNodeInfo"}}, "text": "AGENT-BASED AI\nI don\u2019t use the term \u201cagents\u201d very much in this book, even though \nthe model I\u2019ve described is an agent-based model.\nIn this context, agent-based AI is about producing autonomous \ncharacters that take in information from the game data, determine what \nactions to take based on the information, and carry out those actions.\nIt can be seen as bottom-up design: You start by working out how \neach character will behave and by implementing the AI needed to \nsupport that. The overall behavior of the game is then a function of \nhow the individual character behaviors work together. The first two \nelements of the AI model we\u2019ll use, movement and decision-making, \nmake up the AI for an agent in the game.\nIn contrast, a non-agent-based AI seeks to work out how everything \nought to act from the top down and builds a single system to simu-\nlate everything. An example is the traffic and pedestrian simulation in \nthe cities of Grand Theft Auto 3. The overall traffic and pedestrian flows \nare calculated based on the time of day and city region and are only \nturned into individual cars and people when the player can see them.\nThe distinction is hazy, however. A good AI developer will mix and \nmatch any reliable techniques that get the job done, regardless of the \napproach. That pragmatic approach is the one I always follow. So, I \navoid using agent-based terminology and prefer to talk about game \ncharacters in general, however they are structured.\n\n\nDOI: 10.1201/9781003124047-4\n3\nALGORITHMS AND DATA \nSTRUCTURES\nThere are three key elements to implementing game AI techniques: \nthe algorithm itself, the data structures that the algorithm depends \non, and the way the game world is represented to the algorithm \n(often encoded as an appropriate data structure).\nALGORITHMS\nAlgorithms are step-by-step processes that generate a solution to an \nAI problem. For example algorithms that generate routes through a \ngame level to reach a goal, algorithms that work out which direction \nto move to intercept a fleeing enemy, and algorithms that learn what \nthe player should do next.\nData structures are the other side of the coin to algorithms. They \nhold data in such a way that an algorithm can rapidly manipulate \nit to reach a solution. Often, data structures need to be tuned for \none particular algorithm, and their execution speeds are intrinsically \nlinked.\nYou will need to know a set of elements to implement and tune \nan algorithm, and these include:\n\n18\u2002 \u2009ALGORITHMS AND DATA STRUCTURES\n\u2022 The problem that the algorithm tries to solve\n\u2022 A general description of how the solution works, including dia-\ngrams where they are needed\n\u2022 A pseudo-code presentation of the algorithm\n\u2022 An indication of the data structures required to support the algo-\nrithm, including pseudo-code, where required\n\u2022 Implementation advice, where needed\n\u2022 Analysis of the algorithm performance: its execution speed, mem-\nory footprint, and scalability\n\u2022 Weaknesses in the approach\nPERFORMANCE CHARACTERISTICS\nExecution speed and memory consumption often depend on the size \nof the problem being considered. The standard O() notation is used \nto indicate the order of the most significant element in this scaling.\nAn algorithm might be described as being O(n log n) in execution \nand O(n) in memory, where n is usually some kind of component of \nthe problem, such as the number of other characters in the area, or \nthe number of power-ups in the level.\nA good text on general algorithms for computer science will give \na full mathematical treatment of how O() values are arrived at and \nthe implications they have for the real-world performance of an \nalgorithm.\nSome algorithms have misleading performance characteristics. \nIt is possible to set up highly improbable situations to deliberately \nmake them perform poorly. In regular use (and certainly in any \nuse you\u2019re likely to have in a game), they will have much better \nperformance. \nPSEUDO-CODE\nAlgorithms are often presented in pseudo-code for brevity and sim-\nplicity. Pseudo-code is an imaginary programming language that cuts \nout any implementation details particular to any real programming \n\nALGORITHMS AND DATA STRUCTURES\u2002 \u200919\nlanguage. It should describe the algorithm in sufficient detail so you \ncan implement it in the language of your choice.\nMany AI algorithms need to work with relatively sophisticated \ndata structures: lists, tables, priority queues, associative arrays, and so \non. Some languages provide these built-in; others make them availa-\nble as libraries, or accessed through functions. To make what is going \non clearer, the pseudo-code treats these data structures as if they were \npart of the language, simplifying the code significantly.", "mimetype": "text/plain", "start_char_idx": 29072, "end_char_idx": 33794, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8c6896c5-4a08-482a-99ba-28e93e228ed4": {"__data__": {"id_": "8c6896c5-4a08-482a-99ba-28e93e228ed4", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "33c6bf02-982f-4910-a426-54e2e05488a4", "node_type": "1", "metadata": {}, "hash": "61d0fbf6141e8bf538e51de925a25663c944a770418c1ea695f31bcc4476c2f3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "626cd07d-d4ed-4743-877d-eb7136654ca7", "node_type": "1", "metadata": {}, "hash": "89bd5ee03ab0bf4ff679f0af6936a518b415ac5d3ef085db46ce1c36e5202963", "class_name": "RelatedNodeInfo"}}, "text": "In regular use (and certainly in any \nuse you\u2019re likely to have in a game), they will have much better \nperformance. \nPSEUDO-CODE\nAlgorithms are often presented in pseudo-code for brevity and sim-\nplicity. Pseudo-code is an imaginary programming language that cuts \nout any implementation details particular to any real programming \n\nALGORITHMS AND DATA STRUCTURES\u2002 \u200919\nlanguage. It should describe the algorithm in sufficient detail so you \ncan implement it in the language of your choice.\nMany AI algorithms need to work with relatively sophisticated \ndata structures: lists, tables, priority queues, associative arrays, and so \non. Some languages provide these built-in; others make them availa-\nble as libraries, or accessed through functions. To make what is going \non clearer, the pseudo-code treats these data structures as if they were \npart of the language, simplifying the code significantly.\nAs an example, the following sample is pseudo-code for a simple \nalgorithm to select the highest value from an unsorted array:\nfunction maximum(array:float[]) -> float:\n    max: float = array[0]\n    for element in array[1..]:\n        if element > max:\n            max = element\n    return max\nREPRESENTATIONS\nInformation in the game often needs to be turned into a suitable \nformat for use by the AI. Often, this means converting it to a differ-\nent representation or data structure. The game might store the level \nas meshes of 3D geometry and the character positions as (x, y, z) \nlocations in the world.\nConverting between these representations is a critical process \nbecause it often loses information (that\u2019s the point: to simplify out \nthe irrelevant details), and you always run the risk of losing the \nwrong bits of data. Choosing the correct representation is a key ele-\nment of implementing AI, and certain representations are particu-\nlarly important in game AI.\nAlthough very similar to a data structure, we will often not worry \ndirectly about how the representation is implemented, but instead \nwill focus on the interface it presents to the AI code. This makes it \neasier for you to integrate the AI techniques into your game, simply \nby creating the right glue code to turn your game data into the rep-\nresentation needed by the algorithms.\n\n20\u2002 \u2009ALGORITHMS AND DATA STRUCTURES\nFor example, imagine we want to work out if a character feels \nhealthy or not as part of some algorithm for determining its actions. \nWe might simply require a representation of the character with a \nmethod we can call:\nclass Character:\n    # Return true if the character feels healthy, \nand false otherwise.\n    function feelsHealthy() -> bool\nYou may then implement this by checking against the character\u2019s \nhealth score, by keeping a Boolean \u201chealthy\u201d value for each charac-\nter, or even by running a whole algorithm to determine the charac-\nter\u2019s psychological state and its perception of its own health. As far as \nthe decision making routine is concerned, it doesn\u2019t matter how the \nvalue is being generated.\nThe pseudo-code defines an interface (in the object-oriented \nsense) that can be implemented in any way you choose.\nIMPLEMENTATION\nEven a decade ago, most developers used C++ for their AI code. A \ndecade before that, a significant number relied on C. Games develop-\nment is much more varied now: Swift and Java for mobile platforms, \nC# for the unity game engine, and JavaScript on the web. There are \nmany other languages used here and there in game development: \nLisp, Lua, or Python, particularly as scripting languages; ActionScript \nfor the few remaining Flash developers. I\u2019ve personally worked with \nall these languages at one point or another, so I\u2019ve tried to be as \nlanguage independent as possible, while still giving some advice on \nimplementation.\nOf these, C and C++ are still used for code that absolutely, posi-\ntively has to run as fast as possible. In places, some of the discussion \nof data structures and optimizations will focus on C++, because the \noptimizations are C++ specific.\n\nDOI: 10.1201/9781003124047-5\n4\nGAME AI\nThis chapter looks at the high-level issues around game AI: What \nkinds of approaches work, what they need to take account of, and \nhow they can all be put together.\nTHE COMPLEXITY FALLACY\nIt is a common mistake to think that the more complex the AI in \na game, the better the characters will look to the player. Creating \ngood AI is all about matching the requirements of the game to the \nright behaviors and the right algorithms to produce them. There is \na bewildering array of techniques, and the right one isn\u2019t always the \nmost obvious choice.", "mimetype": "text/plain", "start_char_idx": 32892, "end_char_idx": 37496, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "626cd07d-d4ed-4743-877d-eb7136654ca7": {"__data__": {"id_": "626cd07d-d4ed-4743-877d-eb7136654ca7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c6896c5-4a08-482a-99ba-28e93e228ed4", "node_type": "1", "metadata": {}, "hash": "96c662a3db778276f9e9d2b9005d86ba577dc80044cca5cb283408ac8c70a294", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9cd4157f-d7b0-4480-82ae-e0320ee9117a", "node_type": "1", "metadata": {}, "hash": "232f4d01ccacefe31d943ff4ed11143c4bb3e9dbe2618b01de7759571f1115e4", "class_name": "RelatedNodeInfo"}}, "text": "In places, some of the discussion \nof data structures and optimizations will focus on C++, because the \noptimizations are C++ specific.\n\nDOI: 10.1201/9781003124047-5\n4\nGAME AI\nThis chapter looks at the high-level issues around game AI: What \nkinds of approaches work, what they need to take account of, and \nhow they can all be put together.\nTHE COMPLEXITY FALLACY\nIt is a common mistake to think that the more complex the AI in \na game, the better the characters will look to the player. Creating \ngood AI is all about matching the requirements of the game to the \nright behaviors and the right algorithms to produce them. There is \na bewildering array of techniques, and the right one isn\u2019t always the \nmost obvious choice.\nCountless examples of difficult-to-implement, complex AI have \nresulted in poor, or even stupid-looking behavior. Equally, a very \nsimple technique can be perfect, when used well.\nWHEN SIMPLE THINGS LOOK GOOD\nAs mentioned earlier, Pac-Man was one of the first games with any \nform of character AI. The AI has three states: one normal state when \nthe player is collecting pips; a second state when the player has eaten \nthe power-up and is out for revenge; and a final state that triggers at \ntimed intervals, to have the ghosts back off a little.\n\n22\u2002 \u2009GAME AI\nIn all three states, each of the four ghosts has a target. It moves \nin a straight line until it reaches a junction, then chooses whichever \nroute is closest to the direction of its target. It doesn\u2019t attempt to plan \nthe entire route, or even check its target can be reached, it just moves \ntoward it. In their chasing state, when hunting the player, each ghost \nhas its own simple snippet of code to choose a target. Blinky (the red \nghost) always targets the player position. Pinky (the pink one, obvi-\nously) targets a square four spaces in front of the player, even if that \nis inside or on the other side of a wall. Inky (light blue) uses a modi-\nfied offset of its own and the player\u2019s position. Clyde (orange) targets \nthe player if they are far away, or the corner of the board if close. All \nthese targeting routines can be implemented in a line or two of code.\nThis is about as simple as you can imagine an AI for a moving \ncharacter. Any simpler and the ghosts would be either very predict-\nable (if they always homed in) or purely random. On their own, \nthe ghosts strategy can be easily predicted; their AI does not pose \na challenge. But together, the different behaviors of each ghost are \nenough to make a significant opposing force\u2014so much so that the \nAI to this day gets flattering comments. For example, this comment \nrecently appeared on a website: \u201cTo give the game some tension, \nsome clever AI was programmed into the game. The ghosts would \ngroup up, attack the player, then disperse. Each ghost had its own AI.\u201d\nOther players have reported strategies among the ghosts: \u201cThe \nfour of them are programmed to set a trap, with Blinky leading the \nplayer into an ambush where the other three lie in wait.\u201d\nA simple AI, done well, can appear to a player to be much more \nintelligent than it is.\nThe same thing has been reported by many other developers on \nown their games. As an extreme example, a few years ago Chris King-\nsley of Rebellion mentioned an unpublished Nintendo Game Boy \ntitle in which particular enemy characters simply home in on the \nplayer, but for variation, sidestep at random intervals as they move \nforward. Players reported that these characters \u201canticipated\u201d their fir-\ning patterns and dodged out of the way.\n\nGAME AI\u2002 \u200923\nThe AI wasn\u2019t anticipating anything, and only managed to dodge \nby coincidence some of the time. But a timely sidestep at a crucial \nmoment stayed in the player\u2019s mind and shaped their perception of \nthe AI.\nWHEN COMPLEX THINGS LOOK BAD\nOf course, the opposite thing can easily happen. A game that I looked \nforward to immensely was Herdy Gerdy, one of the launch games Sony \nused to tout the new gameplay possibilities of the \u201cemotion engine\u201d \nchip in their PlayStation 2 hardware. The game is a herding game. \nAn ecosystem of characters is present in the game level. The player \nhas to herd individuals of different species into their corresponding \npens.", "mimetype": "text/plain", "start_char_idx": 36771, "end_char_idx": 40986, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9cd4157f-d7b0-4480-82ae-e0320ee9117a": {"__data__": {"id_": "9cd4157f-d7b0-4480-82ae-e0320ee9117a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "626cd07d-d4ed-4743-877d-eb7136654ca7", "node_type": "1", "metadata": {}, "hash": "89bd5ee03ab0bf4ff679f0af6936a518b415ac5d3ef085db46ce1c36e5202963", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eb6dc8b4-1032-4930-9b10-d06e1cf101e0", "node_type": "1", "metadata": {}, "hash": "1c20bbb1388a2090584c4f1641e48930c7b638139915e63d788e9adccb93d6a1", "class_name": "RelatedNodeInfo"}}, "text": "Players reported that these characters \u201canticipated\u201d their fir-\ning patterns and dodged out of the way.\n\nGAME AI\u2002 \u200923\nThe AI wasn\u2019t anticipating anything, and only managed to dodge \nby coincidence some of the time. But a timely sidestep at a crucial \nmoment stayed in the player\u2019s mind and shaped their perception of \nthe AI.\nWHEN COMPLEX THINGS LOOK BAD\nOf course, the opposite thing can easily happen. A game that I looked \nforward to immensely was Herdy Gerdy, one of the launch games Sony \nused to tout the new gameplay possibilities of the \u201cemotion engine\u201d \nchip in their PlayStation 2 hardware. The game is a herding game. \nAn ecosystem of characters is present in the game level. The player \nhas to herd individuals of different species into their corresponding \npens. Herding had been used before and has since as a component \nof a bigger game, but in Herdy Gerdy, it constituted all of the gameplay.\nUnfortunately, the characters\u2019 movement AI was not quite up to \nthe challenge of its rich level design. It was easy to get them caught \non the scenery, and their collision detection could leave them stuck \nin irretrievable places. This would be frustrating (though not uncom-\nmon) in any game. But it interacted with the herding AI in a way that \nmade some characters appear unexpectedly unintelligent. Reviews \nwere mixed, and sales lackluster.\nUnlike Herdy Gerdy, Black & White achieved significant sales suc-\ncess. But at places it also suffered from great AI looking bad. The \ngame involves teaching a character what to do by a combination of \nexample and feedback. When people first play through the game, \nthey often end up inadvertently teaching the creature bad habits, \nand in the worst cases, it may become unable to carry out even the \nmost basic actions. By paying more attention to how the creature\u2019s \nAI works, players are able to manipulate it better, but the illusion of \nteaching a real creature can be gone.\nMost of the complex things I\u2019ve seen that looked bad never made \nit to the final game. It is a perennial temptation for developers to use \nthe latest techniques and the most hyped algorithms to implement \n\n24\u2002 \u2009GAME AI\ntheir character AI. Late in development, when a learning AI still can\u2019t \nlearn how to steer a car around a track without driving off at every \ncorner, simpler algorithms come to the rescue and make it into the \ngame\u2019s release.\nKnowing when to be complex and when to stay simple is the \nmost difficult element of the game AI programmer\u2019s art. The best AI \nprogrammers are those who can use a very simple technique to give \nthe illusion of complexity.\nThis is easier when there is a tight feedback loop between imple-\nmentation and game design. A slight modification to the require-\nments can mean a better AI technique can be used, which leads to \na better game. Sometimes this means making the required behavior \nsimpler, to make it much more robust. Unfortunately, with the large \nteam sizes on mass-market PC and console games, it is difficult for \na programmer to have much influence. Indie and mobile games, \nwhose teams are much smaller, though not as small as they were a \nfew years ago, still have more opportunity.\nTHE PERCEPTION WINDOW\nUnless your AI is controlling an ever-present sidekick or a one-on-\none enemy, chances are your player will only come across a character \nfor a short time.\nThis can be a significantly short time for disposable guards whose \nlife purpose is to be shot. More difficult enemies can be on-screen \nfor a few minutes as their downfall is plotted and executed.\nWhen we seek to understand someone in real life, we naturally put \nourselves into their shoes. We look at their surroundings, the informa-\ntion they are gleaning from their environment, and the actions they \nare carrying out. The same happens with game characters. A guard \nstanding in a dark room hears a noise: \u201cI\u2019d flick the light switch,\u201d we \nthink. If the guard doesn\u2019t do that, we might assume they are stupid.\nIf we only catch a glimpse of someone for a short while, we don\u2019t \nhave enough time to understand their situation. If we see a guard who \nhas heard a noise suddenly turn away and move slowly in the opposite \n\nGAME AI\u2002 \u200925\ndirection, we assume the AI is faulty. The guard should have moved \nacross the room toward the noise. If we observed them for longer \nto see the guard head over to a light switch by the exit, their action \nwould be understandable.", "mimetype": "text/plain", "start_char_idx": 40211, "end_char_idx": 44633, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eb6dc8b4-1032-4930-9b10-d06e1cf101e0": {"__data__": {"id_": "eb6dc8b4-1032-4930-9b10-d06e1cf101e0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9cd4157f-d7b0-4480-82ae-e0320ee9117a", "node_type": "1", "metadata": {}, "hash": "232f4d01ccacefe31d943ff4ed11143c4bb3e9dbe2618b01de7759571f1115e4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5606b253-28f1-427f-ae7a-b56b8fce61ac", "node_type": "1", "metadata": {}, "hash": "2f1dbd2cb66017e4a6ccd492e764f8c2f48c4074e1dc546c7e07140649ee3d9e", "class_name": "RelatedNodeInfo"}}, "text": "We look at their surroundings, the informa-\ntion they are gleaning from their environment, and the actions they \nare carrying out. The same happens with game characters. A guard \nstanding in a dark room hears a noise: \u201cI\u2019d flick the light switch,\u201d we \nthink. If the guard doesn\u2019t do that, we might assume they are stupid.\nIf we only catch a glimpse of someone for a short while, we don\u2019t \nhave enough time to understand their situation. If we see a guard who \nhas heard a noise suddenly turn away and move slowly in the opposite \n\nGAME AI\u2002 \u200925\ndirection, we assume the AI is faulty. The guard should have moved \nacross the room toward the noise. If we observed them for longer \nto see the guard head over to a light switch by the exit, their action \nwould be understandable. Then again, the guard might not flick on \nthe light switch after all, and we might take that as a sign of poor \nimplementation. But the guard may know that the light is inoperable, \nor they may have been waiting for a colleague to slip some cigarettes \nunder the door and thought the noise was a predefined signal. If we \nknew all that, we\u2019d know the action was intelligent after all.\nThis no-win situation is the perception window. You need to \nmake sure that a character\u2019s AI matches its purpose in the game and \nthe attention it will get from the player. Adding more AI to inci-\ndental characters might endear you to the rare gamer who spends \nhours analyzing each level, checking for curious behavior or bugs, \nbut everyone else (including the publisher and the press) may think \nyour programming was sloppy.\nCHANGES OF BEHAVIOR\nThe perception window isn\u2019t only about time. Think about the ghosts \nin Pac-Man again. They might not give the impression of sentience, \nbut they don\u2019t do anything out of place. This is because they rarely \nchange behavior (the most noticeable is their transformation when \nthe player eats a power-up).\nWhenever a character in a game changes behavior, the change \nis far more conspicuous than the behavior itself. In the same way, \nwhen a character\u2019s behavior should obviously change and doesn\u2019t, \nit draws attention. If two guards are standing talking to each other \nand you shoot one down, the other guard shouldn\u2019t carry on the \nconversation!\nA change in behavior almost always occurs when the player is \nnearby or has been spotted. This is the same in platform games as it \nis in real-time strategy. A good solution is to keep only two behav-\niors for incidental characters\u2014a normal action and a player-spotted \naction.\n\n26\u2002 \u2009GAME AI\nTHE KIND OF AI IN GAMES\nGames have always come under criticism for being poorly pro-\ngrammed, in a software engineering sense: They use tricks, arcane \noptimizations, and unproven technologies to get extra speed or neat \neffects. Though game engines may be reused, gameplay code usually \nisn\u2019t (or at least isn\u2019t written with that in mind) and strong time \npressures mean programmers often do whatever they need to get the \ngame done. Game AI is no different.\nThere is a big gulf between what qualifies as AI in games (i.e., \nwhat is the responsibility of an AI programmer) and what the rest of \nthe programming industry or academia considers to be AI.\nIn my experience, AI for a game is equal parts hacking (ad hoc \nsolutions and neat effects), heuristics (rules of thumb that only work \nin most, but not all, cases), and algorithms (the \u201cproper\u201d stuff). The \nlast group are the techniques we can generalize, examine analytically, \nuse in multiple games, and build into an AI engine.\nBut ad hoc solutions and heuristics are just as important and \ncan breathe as much life into characters as the most complicated \nalgorithm.\nHACKS\nThere\u2019s a saying that goes \u201cIf it looks like a fish and swims like a fish, \nit\u2019s probably a fish.\u201d We understand a behavior by replicating it to a \nsufficient accuracy.\nAs a psychological approach, it has some pedigree (it is related to \nthe behaviorist school of psychology), but has largely been super-\nseded. This fall from fashion has influenced psychological approaches \nto AI, as well. At one point, it was quite acceptable to learn about \nhuman intelligence by making a machine to replicate it, but now that \nis considered poor science. And with good reason, after all, building \na machine to play skillful Chess involves algorithms that evaluate \nmillions of board positions. Human beings are simply not capable \nof this.", "mimetype": "text/plain", "start_char_idx": 43859, "end_char_idx": 48265, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5606b253-28f1-427f-ae7a-b56b8fce61ac": {"__data__": {"id_": "5606b253-28f1-427f-ae7a-b56b8fce61ac", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb6dc8b4-1032-4930-9b10-d06e1cf101e0", "node_type": "1", "metadata": {}, "hash": "1c20bbb1388a2090584c4f1641e48930c7b638139915e63d788e9adccb93d6a1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cab15ee7-e476-40e7-9b35-494889f732ee", "node_type": "1", "metadata": {}, "hash": "4fe40c6265ceeb5715275c6d471fc38afac8279d47538272079ded92151b1a41", "class_name": "RelatedNodeInfo"}}, "text": "But ad hoc solutions and heuristics are just as important and \ncan breathe as much life into characters as the most complicated \nalgorithm.\nHACKS\nThere\u2019s a saying that goes \u201cIf it looks like a fish and swims like a fish, \nit\u2019s probably a fish.\u201d We understand a behavior by replicating it to a \nsufficient accuracy.\nAs a psychological approach, it has some pedigree (it is related to \nthe behaviorist school of psychology), but has largely been super-\nseded. This fall from fashion has influenced psychological approaches \nto AI, as well. At one point, it was quite acceptable to learn about \nhuman intelligence by making a machine to replicate it, but now that \nis considered poor science. And with good reason, after all, building \na machine to play skillful Chess involves algorithms that evaluate \nmillions of board positions. Human beings are simply not capable \nof this.\n\nGAME AI\u2002 \u200927\nOn the other hand, as AI engineers, we are not paid to be inter-\nested in the nature of reality or mind; we want characters that look \nright. In most cases, this means starting from human behaviors and \ntrying to work out the easiest way to implement them in software.\nGood AI in games usually works in this direction. Developers \nrarely build a great new algorithm and then ask themselves, \u201cso what \ncan I do with this?\u201d Instead, you start with a design for a character \nand apply the most relevant tool to get the result.\nThis means that what qualifies as game AI may be unrecogniza-\nble as an AI technique. A simple random number generator applied \njudiciously can produce a lot of believability. Generating a random \nnumber isn\u2019t an AI technique as such. In most languages, there are \nbuilt-in functions to get a random number, so there is certainly no \npoint giving an algorithm for it! But it can work in a surprising \nnumber of situations.\nAnother good example of creative AI development is The Sims. \nWhile there are reasonably complicated things going on under the \nsurface, a lot of the character behavior is communicated with ani-\nmation. Remove the character animation, and the AI would look far \nless impressive. In Star Wars Episode 1: Racer, characters who are annoyed \ngave a little sideswipe to other characters. Quake II introduced the \n\u201cgesture\u201d command, now used in a vast range of first-person games, \nwhere characters (and players) can flip their enemy off. All these \nrequire no significant AI infrastructure. They don\u2019t need complicated \ncognitive models, learning, or neural networks. They just need a few \nlines of code that schedule an animation at the appropriate time.\nAlways be on the lookout for simple things that can give the illu-\nsion of intelligence. If you want engaging emotional characters, is it \npossible to add a couple of emotion animations (a frustrated rub of \nthe temple, perhaps, or a stamp of the foot) to your game? Trigger-\ning these in the right place is much easier than trying to represent \nthe character\u2019s emotional state through their actions. Do you have a \nportfolio of behaviors that the character will choose from? Will the \nchoice involve complex weighing of many factors? If so, it might \nbe worth trying a version of the AI that picks a behavior purely at \n\n28\u2002 \u2009GAME AI\nrandom (maybe with different probabilities for each behavior). You \nmight be able to tell the difference, but your customers may not; so \ntry it out before you code the complex version.\nHEURISTICS\nA heuristic is a rule of thumb, an approximate solution that might \nwork in many situations but is unlikely to work in all.\nHuman beings use heuristics all the time. We don\u2019t try to work \nout all the consequences of our actions. Instead, we rely on general \nprinciples that we\u2019ve found to work in the past (or that we have \nbeen taught or even brainwashed with, equally). It might range from \nsomething as simple as \u201cif you lose something then retrace your \nsteps to look for it\u201d to heuristics that govern our life choices, such as \n\u201cnever trust a used-car salesman.\u201d\nHeuristics have been codified and incorporated into some of the \nalgorithms in this book, and saying \u201cheuristic\u201d to an AI programmer \noften conjures up images of pathfinding or goal-oriented behaviors. \nBeyond these, many of the techniques in this book rely on heuristics \nthat may not always be explicit. There is a trade-off between speed \nand accuracy in areas such as decision-making, movement, and tacti-\ncal thinking (including board game AI).", "mimetype": "text/plain", "start_char_idx": 47390, "end_char_idx": 51827, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cab15ee7-e476-40e7-9b35-494889f732ee": {"__data__": {"id_": "cab15ee7-e476-40e7-9b35-494889f732ee", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5606b253-28f1-427f-ae7a-b56b8fce61ac", "node_type": "1", "metadata": {}, "hash": "2f1dbd2cb66017e4a6ccd492e764f8c2f48c4074e1dc546c7e07140649ee3d9e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1f4431ec-283e-4d4a-a00c-7c108a4ef9fb", "node_type": "1", "metadata": {}, "hash": "5083f29f5dbe85758ffc9318c5f53adf08c38a1b0d88ba2b5a282ed4ac9cd754", "class_name": "RelatedNodeInfo"}}, "text": "We don\u2019t try to work \nout all the consequences of our actions. Instead, we rely on general \nprinciples that we\u2019ve found to work in the past (or that we have \nbeen taught or even brainwashed with, equally). It might range from \nsomething as simple as \u201cif you lose something then retrace your \nsteps to look for it\u201d to heuristics that govern our life choices, such as \n\u201cnever trust a used-car salesman.\u201d\nHeuristics have been codified and incorporated into some of the \nalgorithms in this book, and saying \u201cheuristic\u201d to an AI programmer \noften conjures up images of pathfinding or goal-oriented behaviors. \nBeyond these, many of the techniques in this book rely on heuristics \nthat may not always be explicit. There is a trade-off between speed \nand accuracy in areas such as decision-making, movement, and tacti-\ncal thinking (including board game AI). When accuracy is sacrificed, \nit is usually by replacing search for a correct answer with a heuristic.\nA wide range of heuristics can be applied to general AI problems \nthat don\u2019t require a particular algorithm.\nIn our perennial Pac-Man example, the ghosts move by taking the \nroute at a junction that leads toward their current target. They don\u2019t \nattempt to calculate the best route: either the shortest or fastest. That \nmight be quite complex and involve turning back on oneself, and it \nmight be ultimately redundant as the position of the player continues \nto change. But the rule of thumb (move in the current direction of \nthe target) works most of the time and provides sufficient compe-\ntence for the player to understand that the ghosts aren\u2019t purely ran-\ndom in their motion.\n\nGAME AI\u2002 \u200929\nIn World of WarCraft (and many other RTS games that followed), \nthere is a heuristic that moves a character forward slightly so they can \nengage an enemy standing a fraction beyond the character\u2019s reach. \nWhile this worked in most cases, it wasn\u2019t always the best option. \nMany players got frustrated as comprehensive defensive structures \nwent walkabout when enemies came close. Later, RTS games allowed \nthe player to choose whether this behavior was switched on or not.\nIn many strategic games, including board games, different units \nor pieces are given a single numeric value to represent how \u201cgood\u201d \nthey are. In Chess, pawns are often given one point, bishops and \nknights three, rooks five, and the queen eight. This is a heuristic; it \nreplaces complex calculations about the capabilities of a unit with a \nsingle number. And the number can be defined by the programmer \nin advance. The AI can work out which side is ahead simply by add-\ning the numbers. In an RTS, it can find the best value offensive unit to \nbuild by comparing the number with the cost. A lot of useful effects \ncan be achieved just by manipulating the number.\nThere isn\u2019t an algorithm or a technique for this. And you won\u2019t \nfind it in published AI research. But it is the bread and butter of an \nAI programmer\u2019s job.\nCOMMON HEURISTICS\nA handful of heuristics appear over and over. They are good starting \npoints when initially tackling a problem.\nMOST CONSTRAINED\nGiven the current state of the world, one item in a set needs to be \nchosen. The item chosen should be the one that would be an option \nfor the fewest number of states.\nFor example, a squad of characters engages a group of enemies. \nOne of the enemies is wearing a type of armor that only one rifle can \npenetrate. One squad member has this rifle. When they select who \n\n30\u2002 \u2009GAME AI\nto attack, the most constrained heuristic comes into play; only one \nsquad member can attack this enemy, so that is the action that they \nshould take. Even if their weapon would be more powerful against \ndifferent enemy, their squad mates should handle the others.\nDO THE MOST DIFFICULT THING FIRST\nThe hardest thing to do often has implications for lots of other \nactions. It is better to do this first, rather than find that the easy stuff \ngoes well but is ultimately wasted.\nFor example, an army has two squads with empty slots. The com-\nputer schedules the creation of five Orc warriors and a huge Stone \nTroll. It wants to end up with balanced squads. How should it assign \nthe units to squads? The Stone Troll requires the most slots, so is the \nhardest to assign. It should be placed first.\nIf the Orcs were assigned first, they would be balanced between \nthe two squads, leaving room for half a Troll in each squad, but \nnowhere for the Troll to go.", "mimetype": "text/plain", "start_char_idx": 50976, "end_char_idx": 55417, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1f4431ec-283e-4d4a-a00c-7c108a4ef9fb": {"__data__": {"id_": "1f4431ec-283e-4d4a-a00c-7c108a4ef9fb", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cab15ee7-e476-40e7-9b35-494889f732ee", "node_type": "1", "metadata": {}, "hash": "4fe40c6265ceeb5715275c6d471fc38afac8279d47538272079ded92151b1a41", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2adc2031-6d46-493a-9cd1-2a492cd385fe", "node_type": "1", "metadata": {}, "hash": "ab0aed66cd3ae83feab0d18380b160fd32bd84c04c9676b4a767a7742384550c", "class_name": "RelatedNodeInfo"}}, "text": "Even if their weapon would be more powerful against \ndifferent enemy, their squad mates should handle the others.\nDO THE MOST DIFFICULT THING FIRST\nThe hardest thing to do often has implications for lots of other \nactions. It is better to do this first, rather than find that the easy stuff \ngoes well but is ultimately wasted.\nFor example, an army has two squads with empty slots. The com-\nputer schedules the creation of five Orc warriors and a huge Stone \nTroll. It wants to end up with balanced squads. How should it assign \nthe units to squads? The Stone Troll requires the most slots, so is the \nhardest to assign. It should be placed first.\nIf the Orcs were assigned first, they would be balanced between \nthe two squads, leaving room for half a Troll in each squad, but \nnowhere for the Troll to go.\nTRY THE MOST PROMISING THING FIRST\nIf there are a number of options open to the AI, it is often possible \nto give each one a really rough-and-ready score. Even if this score \nis dramatically inaccurate, trying the options in decreasing score \norder will provide better performance than trying things purely at \nrandom.\nALGORITHMS\nAnd so we come to the final third of the AI programmer\u2019s job: build-\ning algorithms to support interesting character behavior. Hacks and \nheuristics will get you a long way, but relying on them solely means \nyou\u2019ll have to constantly reinvent the wheel. General bits of AI, such \nas movement, decision-making, and tactical thinking, all benefit \nfrom tried and tested methods that can be endlessly reused.\n\nGAME AI\u2002 \u200931\nJust remember that for every situation where a complex algo-\nrithm is the best way to go, there are likely to be several more where \na simpler hack or heuristic will get the job done.\nSPEED AND MEMORY CONSTRAINTS\nThe biggest constraint on the AI developer\u2019s job is the physical lim-\nitations of the machine. Game AI doesn\u2019t have the luxury of days of \nprocessing time and terabytes of memory. We don\u2019t even have the \nluxury of using all the processor and memory of the computer the \ngame is running on. Other tasks need space and time, such as graph-\nics, sound, networking, and input. In teams where different groups \nof developers have to work on their specialties in parallel, a speed \nand memory budget will be set.\nOne of the reasons AI techniques from academia or commercial \nresearch don\u2019t achieve widespread use is their processing time or \nmemory requirements. An algorithm that might be compelling in a \nsimple demo can slow a production game to a standstill.\nThis section looks at low-level hardware issues related to the \ndesign and construction of AI code. Most of what is contained here \nis general advice for all game code.\nPROCESSOR ISSUES\nThe most obvious limitation on the efficiency of a game is the speed \nof the processor on which it is running. Originally, all the games \nmachines had a single main processor, which was also responsible \nfor graphics. Most game hardware now has several CPUs (several \nprocessing cores on the same piece of silicon, usually), and dedi-\ncated GPUs for processing graphics.\nAs a general rule, CPUs are faster and more flexible, where a GPU \nis more parallel. When the task can be split up into many simple \nsubtasks, all running at the same time, the tens up to thousands of \nprocessing cores on a GPU can be orders of magnitude faster than the \nsame task running sequentially on the CPU.\n\n32\u2002 \u2009GAME AI\nGraphics card drivers used to have \u201cfixed function\u201d pipelines, \nwhere the graphics code was built into the driver, and could only \nbe tweaked within narrow parameters. It was impossible to do very \nmuch other than graphics on the graphics card. Now drivers support \ntechnologies such as Vulkan, DirectX 11, CUDA, and OpenCL, which \nallow general-purpose code to be executed on the GPU. As a result, \nmore functionality has been moved to the GPU, freeing up more \nprocessing power on the CPU.\nThe share of the processing time dedicated to AI has grown in fits \nand starts over the last two decades, in some cases now making up \nmost of the CPU load, with some AI running on the GPU. Along with \nthe increase in processor speeds, this is obviously good news for \nAI developers wanting to apply more complicated algorithms, par-\nticularly to decision-making and strategizing. But, while incremen-\ntal improvements in processor time help unlock new techniques, \nthey don\u2019t solve the underlying problem. Many AI algorithms take a \nlong time to run. A comprehensive pathfinding system can take tens \nof milliseconds to run per character.", "mimetype": "text/plain", "start_char_idx": 54610, "end_char_idx": 59155, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2adc2031-6d46-493a-9cd1-2a492cd385fe": {"__data__": {"id_": "2adc2031-6d46-493a-9cd1-2a492cd385fe", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1f4431ec-283e-4d4a-a00c-7c108a4ef9fb", "node_type": "1", "metadata": {}, "hash": "5083f29f5dbe85758ffc9318c5f53adf08c38a1b0d88ba2b5a282ed4ac9cd754", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c21eceb4-6c56-4412-b88b-9ad691ca8c66", "node_type": "1", "metadata": {}, "hash": "c804af6645bf1d1dfb191a217b9276b4afa5c2cf57f4449a42655692cfb0e03e", "class_name": "RelatedNodeInfo"}}, "text": "Now drivers support \ntechnologies such as Vulkan, DirectX 11, CUDA, and OpenCL, which \nallow general-purpose code to be executed on the GPU. As a result, \nmore functionality has been moved to the GPU, freeing up more \nprocessing power on the CPU.\nThe share of the processing time dedicated to AI has grown in fits \nand starts over the last two decades, in some cases now making up \nmost of the CPU load, with some AI running on the GPU. Along with \nthe increase in processor speeds, this is obviously good news for \nAI developers wanting to apply more complicated algorithms, par-\nticularly to decision-making and strategizing. But, while incremen-\ntal improvements in processor time help unlock new techniques, \nthey don\u2019t solve the underlying problem. Many AI algorithms take a \nlong time to run. A comprehensive pathfinding system can take tens \nof milliseconds to run per character. Clearly, in an RTS with 1000 \ncharacters, there is no chance of running each frame. Complex AI \nthat does work in games needs to be split into bite-size components \nthat can be distributed over multiple frames. The chapter on resource \nmanagement shows how to accomplish this. Applying these tech-\nniques to many long-running AI algorithms can bring them into the \nrealm of practicality.\nLOW-LEVEL CONCERNS\nOne large change in the industry in the last 10 years has been \nthe move away from C++ having a hegemony over game pro-\ngramming. Now, character behavior, game logic, and AI are often \nwritten in higher-level languages such as C#, Swift, Java, or even \nscripting languages. This is significant because these languages \nprovide the programmer less ability to micromanage the perfor-\nmance characteristics of their code. There are AI programmers still \nworking in C++, who still need a good knowledge of the \u201cbare \n\nGAME AI\u2002 \u200933\nmetal\u201d performance characteristics of the processors, but in my \nrecent experience, such programmers tend to be low-level special-\nists working on AI engines: portfolios of functionality designed to \nbe reused in multiple games.\nI will describe three low-level issues briefly: SIMD, superscalar \narchitectures, and virtual functions. In this edition, I will describe \nthem only briefly. In my own professional practice, I haven\u2019t been \ndirectly concerned with any of these for several years.\nSIMD (single instruction, multiple data) are a set of registers on \nmodern hardware large enough to fit several floating point numbers. \nMathematical operators can be applied to these registers, which has \nthe effect of running the same code against multiple pieces of data \nin parallel. This can dramatically speed up some code, particularly \ngeometric reasoning. Although CPUs have dedicated registers for \nSIMD, they provide the best speedup on code that tends to suit the \nGPU. Optimizing for SIMD on the CPU is often redundant, when the \ncode can be moved onto the GPU.\nSuperscalar CPUs have several execution paths active at the same \ntime. Code is split among the parts to execute in parallel, and the \nresults are then recombined into the final result. When the result of \none pipeline depends on another, this can involve either waiting, or \nguessing what the result might be and redoing the work if it proves \nto be wrong (known as branch prediction). In the last decade, multi-core \nCPUs, where several independent CPUs allow different threads to \nrun in parallel, have become almost ubiquitous. Although each core \nmay still be superscalar, this is now largely treated as a behind-the-\nscenes detail, irrelevant to AI programmers. Better speedups can be \nattained by concentrating on making AI code parallelizable, rather \nthan worrying about the details of branch prediction.\nAI code can take advantage of this parallelism either by running \nAI for different characters in different threads or by running all AI \nin a different thread to other game systems. These threads will then \nbe executed in parallel on different cores, when available. Multiple \nthreads doing the same thing (such as one character running its AI in \neach thread) are often more performant, as it is easier to make sure \n\n34\u2002 \u2009GAME AI\nall processors are being used to the same capacity, and more flexible, \nas it scales without rebalancing to hardware with a different number \nof cores.\nWhen AI routinely had to be careful of every single CPU cycle \nused, it was common to avoid virtual classes in C++, with their \nvirtual function call overhead. This meant avoiding object-oriented \npolymorphism, whenever possible. A virtual function call stores the \nmemory location in which the function is implemented in a variable \n(in a structure called a function table, or vtable).", "mimetype": "text/plain", "start_char_idx": 58269, "end_char_idx": 62941, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c21eceb4-6c56-4412-b88b-9ad691ca8c66": {"__data__": {"id_": "c21eceb4-6c56-4412-b88b-9ad691ca8c66", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2adc2031-6d46-493a-9cd1-2a492cd385fe", "node_type": "1", "metadata": {}, "hash": "ab0aed66cd3ae83feab0d18380b160fd32bd84c04c9676b4a767a7742384550c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "35f900bb-ac69-4bf4-939b-6df36541b8b7", "node_type": "1", "metadata": {}, "hash": "180b5a36be24fc49d575ebbe850980f0cc212de525e2b0f47495f9644ef53b45", "class_name": "RelatedNodeInfo"}}, "text": "These threads will then \nbe executed in parallel on different cores, when available. Multiple \nthreads doing the same thing (such as one character running its AI in \neach thread) are often more performant, as it is easier to make sure \n\n34\u2002 \u2009GAME AI\nall processors are being used to the same capacity, and more flexible, \nas it scales without rebalancing to hardware with a different number \nof cores.\nWhen AI routinely had to be careful of every single CPU cycle \nused, it was common to avoid virtual classes in C++, with their \nvirtual function call overhead. This meant avoiding object-oriented \npolymorphism, whenever possible. A virtual function call stores the \nmemory location in which the function is implemented in a variable \n(in a structure called a function table, or vtable). Calling a function \ntherefore involves looking up the variable at runtime, and then look-\ning up the location that variable specifies. Though this extra lookup \nuses a trivial amount of time, it could interact significantly with the \nbranch predictor and processor cache. For this reason, virtual func-\ntions, and hence polymorphism, had a bad reputation. A reputation \nthat has largely faded in the past 10 years. Now, game engines such \nas Unity, Unreal, Lumberyard, and Godot assume that game logic \nwill be polymorphic.\nMEMORY CONCERNS\nMost AI algorithms do not require a large amount of RAM, often \njust a few, up to tens of megabytes. This small storage requirement, \neasily achievable on modest mobile devices, is ample for heavy-\nweight algorithms such as terrain analysis and pathfinding. Massively \nmulti-player online games (MMOGs) typically require much more \nstorage for their larger worlds, but are run on server farms where \nsufficient memory can be installed (even then, we are only talking \ngigabytes of RAM, rarely more). Huge worlds are usually sharded \ninto separate sections, or else characters are limited to certain areas, \nfurther reducing the AI memory requirements.\nSo it is not the amount of memory which is usually the limiting \nfactor, but the way it is used. Allocation and cache coherence are both \nmemory concerns that affect performance. They can both influence \nthe implementation of an AI algorithm.\n\nGAME AI\u2002 \u200935\nALLOCATION AND GARBAGE COLLECTION\nAllocation is the process of asking for memory in which to place \ndata. When that memory is no longer needed, it is said to be freed or \ndeallocated. Allocation and deallocation are relatively fast, as long as \nmemory is available.\nLow-level languages such as C require the programmer to free \nmemory manually. Languages such as C++ and Swift, when memory \nis allocated for a particular object, provide \u201creference counting.\u201d This \nstores the number of places that know about the existence of the \nobject. When the object is no longer referenced, the counter drops \nto 0, and the memory is freed. Unfortunately, both these approaches \ncan mean that memory that should be freed is never freed. Either \nthe programmer forgets to free manually, or there is a circular set \nof references, such that their counters never drop to 0. Many high-\ner-level languages implement sophisticated algorithms to collect this \n\u201cgarbage,\u201d i.e., free memory that is no longer useful. Unfortunately, \ngarbage collection can be expensive. In languages such as C#, par-\nticularly in the Mono runtime that runs the Unity game engine, \ngarbage collection can be slow enough to delay a rendering frame, \ncausing a visual stutter. This is unacceptable to most developers.\nAs a result, implementing AI algorithms for higher-level languages \noften involves trying not to allocate and deallocate objects while a \nlevel is running. The data required for the entire level are reserved \nwhen the level begins, and only released when the level ends. Sev-\neral of the algorithms in this book assume that new objects can be \ncreated at any time, and will be left to disappear when no longer \nneeded. On a platform with time-consuming garbage collection, it \nmay be important to modify these implementations. When the path \nis complete, none of the intermediate location data are needed. A \ngarbage-collection-friendly implementation might create a single \npathfinding object, containing data for every location in the map. \nThat same object is called whenever pathfinding is required, and \nit uses the preallocated location data it needs and ignores the rest. \nOn its own, this implementation will be a little more complicated \n\n36\u2002 \u2009GAME AI\nand could be considerably more complex if multiple characters who \nneed pathfinding must queue to use the one pathfinding object.\nCACHE\nMemory size alone isn\u2019t the only limitation on memory use.", "mimetype": "text/plain", "start_char_idx": 62153, "end_char_idx": 66824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "35f900bb-ac69-4bf4-939b-6df36541b8b7": {"__data__": {"id_": "35f900bb-ac69-4bf4-939b-6df36541b8b7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c21eceb4-6c56-4412-b88b-9ad691ca8c66", "node_type": "1", "metadata": {}, "hash": "c804af6645bf1d1dfb191a217b9276b4afa5c2cf57f4449a42655692cfb0e03e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "25192abd-6043-4c7b-8ced-a4339d7e5f56", "node_type": "1", "metadata": {}, "hash": "cc96b682f4f3b12237a1b600ef8fa1ff266b3eb5c7e5e2ce91967ccdd52608bb", "class_name": "RelatedNodeInfo"}}, "text": "Sev-\neral of the algorithms in this book assume that new objects can be \ncreated at any time, and will be left to disappear when no longer \nneeded. On a platform with time-consuming garbage collection, it \nmay be important to modify these implementations. When the path \nis complete, none of the intermediate location data are needed. A \ngarbage-collection-friendly implementation might create a single \npathfinding object, containing data for every location in the map. \nThat same object is called whenever pathfinding is required, and \nit uses the preallocated location data it needs and ignores the rest. \nOn its own, this implementation will be a little more complicated \n\n36\u2002 \u2009GAME AI\nand could be considerably more complex if multiple characters who \nneed pathfinding must queue to use the one pathfinding object.\nCACHE\nMemory size alone isn\u2019t the only limitation on memory use. The \ntime it takes to access memory from the RAM and prepare it for use \nby the processor is significantly longer than the time it takes for the \nprocessor to perform its operations. If processors had to rely on the \nmain RAM, they\u2019d be constantly stalled waiting for data.\nAll modern processors use at least one level of cache: a copy of \nthe RAM held in the processor that can be very quickly manipulated. \nCache is typically fetched in pages; a whole section of main mem-\nory is streamed to the processor. It can then be manipulated at will. \nWhen the processor has done its work, the cached memory is sent \nback to the main memory. The processor typically cannot work on \nthe main memory: All the memory it needs must be on cache. An \noperating system may add additional complexity to this, as a mem-\nory request may have to pass through an operating system routine \nthat translates the request into a request for real or virtual memory. \nThis can introduce further constraints, as two bits of physical mem-\nory with a similar mapped address might not be available at the same \ntime (called an aliasing failure).\nMultiple levels of cache work the same way as a single cache. A \nlarge amount of memory is fetched to the lowest level cache, a subset \nof that is fetched to each higher-level cache, and the processor only \never works on the highest level.\nIf an algorithm uses data spread around memory, then it is \nunlikely that the right memory will be in the cache from moment to \nmoment. These cache misses are costly in time. The processor has to \nfetch a whole new chunk of memory into the cache for one or two \ninstructions, then it has to stream it all back out and request another \nblock. A good profiling system will show when cache misses are \nhappening. In my experience, even in languages that don\u2019t give you \ncontrol over memory layout, dramatic speedups can be achieved by \n\nGAME AI\u2002 \u200937\nmaking sure that all the data needed for one algorithm are kept in the \nsame place, in the same few objects.\nIn a game with 1,000 characters, it may be better to keep all their \npositions together in an array, so algorithms that make calculations \nbased on location don\u2019t need to constantly jump around memory. \nAs with all optimizations, profiling is everything, but a general level \nof efficiency can be gained by programming with data coherence in \nmind.\nPLATFORMS\nWith the centralization of the industry around a few game engines, \nplatform differences have less of an impact on AI design than they \nused to. Graphics programmers may still have to worry about console \nversus mobile, for example. But AI programming tends to be more \ngeneral. In this section, I will consider each of the major platforms \nfor games, highlighting any issues specific to AI code.\nPC\nPCs can be the most powerful games machines, with hard-core gam-\ners buying high-end expensive hardware. But they can be frustrating \nfor developers because of their lack of consistency. Where a console \nhas fixed hardware (or at least relatively few variations), there is a \nbewildering array of different configurations for PCs. There is a vast \ndifference between a machine with a pair of top of the range video \ncards, SSD drives and fast memory, and a budget PC with integrated \ngraphics.\nThings are easier than they were: Low-level developers rely on \napplication programming interfaces (APIs) such as Vulkan and \nDirectX to insulate them from most hardware specifics, but the game \nstill needs to detect feature support and speed and adjust accordingly. \nDevelopers working in an engine such as Unity and Unreal have it \neven easier, but may still need to use the built-in feature detection to \nensure their game runs well on all systems.", "mimetype": "text/plain", "start_char_idx": 65940, "end_char_idx": 70542, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "25192abd-6043-4c7b-8ced-a4339d7e5f56": {"__data__": {"id_": "25192abd-6043-4c7b-8ced-a4339d7e5f56", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "35f900bb-ac69-4bf4-939b-6df36541b8b7", "node_type": "1", "metadata": {}, "hash": "180b5a36be24fc49d575ebbe850980f0cc212de525e2b0f47495f9644ef53b45", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "38f079ab-a42e-40aa-b5f3-868898d1de34", "node_type": "1", "metadata": {}, "hash": "f6c56324aee93e2140f91a748d9fd93f08aefb493f2d6401c0fb40047af601d7", "class_name": "RelatedNodeInfo"}}, "text": "PC\nPCs can be the most powerful games machines, with hard-core gam-\ners buying high-end expensive hardware. But they can be frustrating \nfor developers because of their lack of consistency. Where a console \nhas fixed hardware (or at least relatively few variations), there is a \nbewildering array of different configurations for PCs. There is a vast \ndifference between a machine with a pair of top of the range video \ncards, SSD drives and fast memory, and a budget PC with integrated \ngraphics.\nThings are easier than they were: Low-level developers rely on \napplication programming interfaces (APIs) such as Vulkan and \nDirectX to insulate them from most hardware specifics, but the game \nstill needs to detect feature support and speed and adjust accordingly. \nDevelopers working in an engine such as Unity and Unreal have it \neven easier, but may still need to use the built-in feature detection to \nensure their game runs well on all systems.\n\n38\u2002 \u2009GAME AI\nWorking with PCs involves building software that can scale from \na casual gamer\u2019s limited system to the hard-core fan\u2019s up-to-date \nhardware. For graphics, this scaling can be reasonably modular; for \nexample, for low-specification machines, we switch off advanced ren-\ndering features. A simpler shadow algorithm might be used, or phys-\nically based shaders might be replaced by simple texture mapping. A \nchange in graphics sophistication usually doesn\u2019t change gameplay.\nAI is different. If the AI gets less time to work, how should it \nrespond? It can try to perform less work. This is effectively the same \nas having more stupid AI and can affect the difficulty level of the \ngame. It is probably not acceptable to have your game be easier on \nlower-specification machines. Similarly, if we try to perform the \nsame amount of work, it might take longer. This can mean a lower \nframe rate, or it can mean more frames between characters mak-\ning decisions. Slow-to-react characters are also often easier to play \nagainst and can cause the same problems with QA.\nThe solution used by most developers is to target AI at the lowest \ncommon denominator: the minimum-specification machine listed \nin the technical design document. The AI time doesn\u2019t scale at all \nwith the capabilities of the machine. Faster machines simply use pro-\nportionally less of their processing budget on AI.\nThere are many games, however, where scalable AI is feasible. \nMany games use AI to control ambient characters: pedestrians walk-\ning along the sidewalk, members of the crowd cheering a race, or \nflocks of birds swarming in the sky. This kind of AI is freely scalable: \nMore characters can be used when the processor time is available.\nCONSOLE\nConsoles can be simpler to work with than a PC. You know exactly \nthe machine you are targeting, and you can usually see code in oper-\nation on your target machine. There is no future proofing for new \nhardware or ever-changing versions of APIs to worry about.\nDevelopers working with next-generation technology often don\u2019t \nhave the exact specs of the final machine or a reliable hardware \n\nGAME AI\u2002 \u200939\nplatform (initial development kits are often little more than a ded-\nicated emulator), but most console development has a fairly fixed \ntarget.\nThe technical requirements checklist (TRC) process, by which a \nconsole manufacturer places minimum standards on the operation of \na game, serves to fix things like frame rates (although different ter-\nritories may vary\u2014PAL and NTSC, for example). This means that AI \nbudgets can be locked down in terms of a fixed number of millisec-\nonds. In turn, this makes it much easier to work out what algorithms \ncan be used and to have a fixed target for optimization (provided \nthat the budget isn\u2019t slashed at the last milestone to make way for the \nlatest graphics technique used in a competitor\u2019s game).\nThe same game engines used for PC development target consoles, \nmaking cross-platform development much easier than it has been \nin the past. Fortunately, few AI developers creating games are now \nworking with the low-level details of a particular console. Almost all \nthe low-level code is handled by engines or middleware.\nMOBILE\nApple launched the iPhone in 2007, ushering in a revolution in \ngaming as big as anything since the home consoles of the 1980s. In \n2006, mobile gaming consisted of dedicated handheld consoles like \nthe PlayStation Portable (PSP) and Nintendo\u2019s Game Boy Advance. \nNow almost 100% of the market is for phones and tablets.\nThere are two platforms in the space: Apple, with its iOS devices \n(iPhone, iPad, iPod Touch), and Android. Until recently, these were \nvery different, and required games to be coded for each individually.", "mimetype": "text/plain", "start_char_idx": 69594, "end_char_idx": 74292, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "38f079ab-a42e-40aa-b5f3-868898d1de34": {"__data__": {"id_": "38f079ab-a42e-40aa-b5f3-868898d1de34", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "25192abd-6043-4c7b-8ced-a4339d7e5f56", "node_type": "1", "metadata": {}, "hash": "cc96b682f4f3b12237a1b600ef8fa1ff266b3eb5c7e5e2ce91967ccdd52608bb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dc530a25-2cc0-4475-a051-d6214e2ba8eb", "node_type": "1", "metadata": {}, "hash": "51cccc85a68077003e1019fcf1fc0fa903cce0ce5cf85662a086bb49e94ac0dd", "class_name": "RelatedNodeInfo"}}, "text": "The same game engines used for PC development target consoles, \nmaking cross-platform development much easier than it has been \nin the past. Fortunately, few AI developers creating games are now \nworking with the low-level details of a particular console. Almost all \nthe low-level code is handled by engines or middleware.\nMOBILE\nApple launched the iPhone in 2007, ushering in a revolution in \ngaming as big as anything since the home consoles of the 1980s. In \n2006, mobile gaming consisted of dedicated handheld consoles like \nthe PlayStation Portable (PSP) and Nintendo\u2019s Game Boy Advance. \nNow almost 100% of the market is for phones and tablets.\nThere are two platforms in the space: Apple, with its iOS devices \n(iPhone, iPad, iPod Touch), and Android. Until recently, these were \nvery different, and required games to be coded for each individually. \nAlthough both can use low-level languages such as C and C++, for \nhigher-level languages Apple encourages the use of Swift (it formerly \nused Objective-C), and Android Java (or languages that compile into \nJava bytecode, such as Kotlin).\nBoth the major game engines by market share (Unreal and Unity), \nas well as many smaller competitors (e.g., Godot), support mobile \nplatforms with the same game code, making platform-specific \n\n40\u2002 \u2009GAME AI\nimplementation unnecessary. There has been a big shift toward \nmobile developers working in a cross-platform way, using these \ntools. Factoring in the Steam platform as a viable marketplace for \nmobile games running on PC, I think there is no doubt this trend \nwill soon become almost ubiquitous.\nSmartphones capable of running games are powerful machines, \ncomparable to last-generation consoles and PCs 5\u201310 years old. \nThere is no longer any practical difference between the kinds of AI \nthat can be run on a PC or console and those that can be run on \nmobile. Phones may require simpler graphics or smaller crowd sizes, \nbut in terms of algorithms, the same things now apply.\nVIRTUAL AND AUGMENTED REALITY\nIn early 2019, virtual and augmented reality are both extremely \nhyped, and a tiny proportion of the games market. The technology \nand the market is in rapid flux, and beyond generalities, very little \nthat could be said now would be true in 2 years.\nVirtual reality (VR) attempts to immerse the player in the game \nworld by providing a stereoscopic 3D point of view. Depending on \nthe hardware, a player\u2019s motion may also be detected and incorpo-\nrated as movement in the game. VR requires separate views of the \nscene to be rendered for each eye, and to avoid motion sickness, \nhigher frame rates are typically targeted (90fps, for example).\nUp to this point, most virtual reality devices have been displays \ntethered to an existing games machine, such as a PC (Oculus Rift \nand Vive), a console (PlayStation VR), or a phone (Gear VR). At the \ntime of writing, companies are beginning to release stand-alone VR \nproducts, based on mobile processors, with approximately similar \nperformance to high-end phones.\nAugmented reality (AR) uses semitransparent displays to add \ncomputer-generated elements to the real world. Although Microsoft \nreleased a development kit in early 2016, a consumer version has \nnot yet followed. Magic Leap released their product in 2018, but saw \nlimited demand. Augmented reality may also refer to games that use \n\nGAME AI\u2002 \u200941\na mobile phone camera, and add computer-generated elements to \nthe captured images. In that sense, Pok\u00e9mon Go, for example, is con-\nsidered an augmented reality game, but does not require specialist \nhardware.\nWhile the visual presentation of VR games may be unconventional, \nthe game logic rarely is. Most commercial game engines support VR, \nAR on mobile via camera, and are positioned to offer hardware AR \nsupport, when products are announced. VR and AR games are similar \nenough in design not to need unusual AI algorithms. It remains to be \nseen whether these platforms open new design possibilities. It also \nremains to be seen whether these platforms become a significant \npart of the industry.\nTHE AI ENGINE\nWhen I started in the industry, a game was mostly built from scratch. \nSome bits of code were dragged from previous projects, and some \nbits were reworked and reused, but most were new. A handful of \ncompanies used the same basic code to write multiple games, as \nlong as the games were a similar style and genre. LucasArts\u2019 SCUMM \nengine, for example, was a gradually evolving game engine used to \npower many point-and-click adventure games.", "mimetype": "text/plain", "start_char_idx": 73435, "end_char_idx": 77966, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dc530a25-2cc0-4475-a051-d6214e2ba8eb": {"__data__": {"id_": "dc530a25-2cc0-4475-a051-d6214e2ba8eb", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "38f079ab-a42e-40aa-b5f3-868898d1de34", "node_type": "1", "metadata": {}, "hash": "f6c56324aee93e2140f91a748d9fd93f08aefb493f2d6401c0fb40047af601d7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b8d1b6a-7f76-466b-90e6-a16ae68ee9f9", "node_type": "1", "metadata": {}, "hash": "13037f3513239f3684404873890b3745ae147127284f99261f3b114369e0f99b", "class_name": "RelatedNodeInfo"}}, "text": "Most commercial game engines support VR, \nAR on mobile via camera, and are positioned to offer hardware AR \nsupport, when products are announced. VR and AR games are similar \nenough in design not to need unusual AI algorithms. It remains to be \nseen whether these platforms open new design possibilities. It also \nremains to be seen whether these platforms become a significant \npart of the industry.\nTHE AI ENGINE\nWhen I started in the industry, a game was mostly built from scratch. \nSome bits of code were dragged from previous projects, and some \nbits were reworked and reused, but most were new. A handful of \ncompanies used the same basic code to write multiple games, as \nlong as the games were a similar style and genre. LucasArts\u2019 SCUMM \nengine, for example, was a gradually evolving game engine used to \npower many point-and-click adventure games.\nSince then, game engines have become ubiquitous, a consistent \ntechnical platform on which multiple games are built. Low-level \nroutines (like talking to the operating system, loading textures, \nmodel file formats, and so on) are shared among all titles, a set of \ntools are available for a broad range of games (e.g., 2D graphics, \n3D graphics, and networking), and finally, interfaces are provided to \nadd game-specific code on top. Originally, these engines belonged to \nindividual companies, but over time, only the very largest companies \ncould afford to keep their engines up-to-date. It is now common for \nlarge developers to license commercial engines.\nThe way AI is developed has changed, also. Initially, the AI was \nwritten for each game and sometimes for each character. Now there \nis an increasing tendency to have general AI routines, either built \n\n42\u2002 \u2009GAME AI\ninto the game engine, available to license as commercial add-ons, or \ncreated and reused in-house by a developer. This allows individual \ncharacters to be designed by level editors, game designers, or techni-\ncal artists. The engine structure is fixed, and the AI for each character \ncombines the components in an appropriate way.\nSo, building a game engine involves building AI tools that can be \neasily reused, combined, and applied in interesting ways. To sup-\nport this, we need an AI structure that makes sense over multiple \ngenres.\nSTRUCTURE OF AN AI ENGINE\nIn my experience, there are a few basic facilities that need to be in \nplace for a general AI system. They conform to the model of AI given \nin Figure 4.1.\nFirst, we must have some kind of infrastructure in two categories: \na general mechanism for managing AI behaviors (deciding which \nbehavior gets to run when, and so on) and a world interfacing \nFigure 4.1 The AI model.\n\nGAME AI\u2002 \u200943\nsystem for getting information into the AI. Every AI algorithm needs \nto honor these mechanisms.\nSecond, we must have a means to turn whatever the AI wants to \ndo into action on-screen. This consists of standard interfaces to a \nmovement and an animation controller, which can turn requests \nsuch as \u201cpull lever 1\u201d or \u201cwalk stealthily to position x, y\u201d into \naction.\nThird, a standard behavior structure must serve as a liaison \nbetween the two. It is almost guaranteed that you will need to write \none or two AI algorithms for each new game. Having all AI con-\nform to the same structure helps this immensely. New code can be in \ndevelopment while the game is running, and the new AI can simply \nreplace placeholder behaviors when it is ready.\nAll this needs to be thought out in advance. The structure needs \nto be in place before you get well into your AI coding. Chapter 6 of \nthis book describes support technologies, which are the first thing \nto implement in an AI engine. The individual techniques can then \nslot in.\nGame engines do some of this for you, but not all. Each engine \nhas its own mechanism to make sure your code is run, often in the \nform of base classes that you should derive from. But you may need \nto provide more fine-grained control: Not every character needs its \nAI run in every frame. They also provide standard mechanisms for \nscheduling animations, but less often character movement. And they \nmay provide basic tools for working out which character knows \nwhat (such as a built-in line of sight or sight cone check), but will \nneed custom implementations for anything more complex. Unless \nyou intend to use very simple techniques, you will need to create \nsome infrastructure, and possibly some tools in the editor to support \nit.\nThere are techniques that can work on their own, and all the \nalgorithms are fairly independent.", "mimetype": "text/plain", "start_char_idx": 77109, "end_char_idx": 81660, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8b8d1b6a-7f76-466b-90e6-a16ae68ee9f9": {"__data__": {"id_": "8b8d1b6a-7f76-466b-90e6-a16ae68ee9f9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dc530a25-2cc0-4475-a051-d6214e2ba8eb", "node_type": "1", "metadata": {}, "hash": "51cccc85a68077003e1019fcf1fc0fa903cce0ce5cf85662a086bb49e94ac0dd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "61c5d146-fcdf-426d-bfc9-47199cab8524", "node_type": "1", "metadata": {}, "hash": "7937b796ae5ec68aa7d93370987fbffd946466e26c8460887469a2f51ac2a4f8", "class_name": "RelatedNodeInfo"}}, "text": "The individual techniques can then \nslot in.\nGame engines do some of this for you, but not all. Each engine \nhas its own mechanism to make sure your code is run, often in the \nform of base classes that you should derive from. But you may need \nto provide more fine-grained control: Not every character needs its \nAI run in every frame. They also provide standard mechanisms for \nscheduling animations, but less often character movement. And they \nmay provide basic tools for working out which character knows \nwhat (such as a built-in line of sight or sight cone check), but will \nneed custom implementations for anything more complex. Unless \nyou intend to use very simple techniques, you will need to create \nsome infrastructure, and possibly some tools in the editor to support \nit.\nThere are techniques that can work on their own, and all the \nalgorithms are fairly independent. For a demo, or a simple game, it \nmight be sufficient to just use the technique. But a good AI struc-\nture helps promote reuse and reduces debugging and development \ntime.\n\n44\u2002 \u2009GAME AI\nTOOL CONCERNS\nThe complete AI engine will have a central pool of AI algorithms \nthat can be applied to many characters. The definition for a particu-\nlar character\u2019s AI will therefore consist of data (which may include \nscripts in some scripting language), rather than compiled code. The \ndata specify how a character is put together: What techniques will \nbe used and how those techniques are parameterized and combined.\nThese data need to come from somewhere. Data can be manually \ncreated, but this is no better than writing the AI by hand each time. \nFlexible tools ensure that the artists and designers can create the con-\ntent in an easy way, while allowing the content to be inserted into \nthe game without manual help. These are usually created as custom \nmodes in the game engine editor: a tool for setting up character \ndecision-making rules, or an overlay onto the level used to mark \ntactical locations or places to avoid.\nThe need to expose search tools has its own effect on the choice of \nAI techniques. It is easy to set up behaviors that always act the same \nway. Steering behaviors are a good example: They tend to be very \nsimple, they are easily parameterized (with the physical capabilities \nof a character), and they do not change from character to character.\nIt is more difficult to use behaviors that have lots of conditions, \nwhere the character needs to evaluate special cases. Those based on \na tree (decision trees and behavior trees) are easier to represent vis-\nually. A rule-based system, on the other hand, needs to have compli-\ncated matching rules defined. When these are supported in a tool, \nthey typically look like program code, because a programming lan-\nguage is the most natural way to express them.\nPUTTING IT ALL TOGETHER\nThe final structure of the AI engine might look something like \nFigure 4.2. Data are created in a tool (the modeling or level editor), \nwhich is then packaged for use in the game. When a level is loaded, \nthe game AI behaviors are created from level data and registered with \n\nGAME AI\u2002 \u200945\nthe AI engine. During gameplay, the main game code calls the AI \nengine which updates the behaviors, getting information from the \nworld interface and finally applying their output to the game data.\nThe particular techniques used depend heavily on the genre of the \ngame being developed. As you develop your game AI, you\u2019ll need to \ntake a mix and match approach to get the behaviors you are looking \nfor.\nFigure 4.2 AI schematic.\n\n\nDOI: 10.1201/9781003124047-6\n5\nTECHNIQUES\nMOVEMENT\nOne of the most fundamental requirements of game AI is to sensibly \nmove characters around. Even the earliest AI-controlled characters \n(the ghosts in Pac-Man, for example, or the opposing bat in some Pong \nvariants) had movement algorithms that weren\u2019t far removed from \nmodern games.\nMovement forms the lowest level of AI techniques in our model, \nas shown in Figure 5.1.\nMany games, including some with quite decent-looking AI, rely \nsolely on movement algorithms and don\u2019t have any more advanced \ndecision-making. At the other extreme, some games don\u2019t need mov-\ning characters at all. Resource management games and turn-based \ngames often don\u2019t need movement algorithms; once a decision is \nmade where to move, the character can simply be placed there.\nThere is also some degree of overlap between AI and animation; \nanimation is also about movement.", "mimetype": "text/plain", "start_char_idx": 80778, "end_char_idx": 85241, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "61c5d146-fcdf-426d-bfc9-47199cab8524": {"__data__": {"id_": "61c5d146-fcdf-426d-bfc9-47199cab8524", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b8d1b6a-7f76-466b-90e6-a16ae68ee9f9", "node_type": "1", "metadata": {}, "hash": "13037f3513239f3684404873890b3745ae147127284f99261f3b114369e0f99b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1db10de4-47e8-4e09-9673-cdae92e1bef0", "node_type": "1", "metadata": {}, "hash": "4a3bce66cc2c3d2ddc8c66b657b65a06bc672ee49c103514b1300407c02548ac", "class_name": "RelatedNodeInfo"}}, "text": "Even the earliest AI-controlled characters \n(the ghosts in Pac-Man, for example, or the opposing bat in some Pong \nvariants) had movement algorithms that weren\u2019t far removed from \nmodern games.\nMovement forms the lowest level of AI techniques in our model, \nas shown in Figure 5.1.\nMany games, including some with quite decent-looking AI, rely \nsolely on movement algorithms and don\u2019t have any more advanced \ndecision-making. At the other extreme, some games don\u2019t need mov-\ning characters at all. Resource management games and turn-based \ngames often don\u2019t need movement algorithms; once a decision is \nmade where to move, the character can simply be placed there.\nThere is also some degree of overlap between AI and animation; \nanimation is also about movement. This chapter looks at large-scale \nmovement: the movement of characters around the game level, \nrather than the movement of their limbs or faces. The dividing line \nisn\u2019t always clear, however. In many games, animation can take con-\ntrol over a character, including some large-scale movement. This may \nbe as simple as the character moving a few steps to pull a lever. Or \n\n48\u2002 \u2009TECHNIQUES\nas complex as mini cut-scenes, completely animated, that seamlessly \ntransition into and out of gameplay.\nTHE BASICS OF MOVEMENT ALGORITHMS\nUnless you\u2019re writing an economic simulator, chances are the char-\nacters in your game need to move around. Each character has a cur-\nrent position and possibly additional physical properties that control \nits movement. A movement algorithm is designed to use these prop-\nerties to work out where the character should be next.\nAll movement algorithms have this same basic form. They take \ngeometric data about their own state and the state of the world, and \nthey come up with a geometric output representing the movement \nthey would like to make. Figure 5.2 shows this schematically. In the \nfigure, the velocity of a character is shown as optional because it is \nonly needed for certain classes of movement algorithms.\nFigure 5.1 The AI model.\n\nTECHNIQUES\u2002 \u200949\nSome movement algorithms require very little input: just the \nposition of the character and the position of an enemy to chase, for \nexample. Others require a lot of interaction with the game state and \nthe level geometry. A movement algorithm that avoids bumping into \nwalls, for example, needs to have access to the geometry of the wall \nto check for potential collisions.\nThe output can vary too. In most games, it is normal to have \nmovement algorithms output a desired velocity. A character might \nsee its enemy to the west, for example, and respond that its move-\nment should be westward at full speed. Often, characters in older \ngames only had two speeds: stationary and running (with maybe \na walk speed in there, too, for patrolling). So the output was sim-\nply a direction to move in. This is kinematic movement; it does not \naccount for how characters accelerate and slow down.\nIt is common now for more physical properties to be taken into \naccount. Producing movement algorithms I will call \u201csteering behav-\niors.\u201d They are not kinematic, but dynamic. Dynamic movement takes \naccount of the current motion of the character. A dynamic algorithm \nFigure 5.2 The movement algorithm structure.\n\n50\u2002 \u2009TECHNIQUES\ntypically needs to know the current velocities of the character as well \nas its position. A dynamic algorithm outputs forces or accelerations \nwith the aim of changing the velocity of the character.\nDynamics adds an extra layer of complexity. Let\u2019s say your charac-\nter needs to move from one place to another. A kinematic algorithm \nsimply gives the direction to the target; your character moves in that \ndirection until it arrives, whereupon the algorithm returns no direc-\ntion. A dynamic movement algorithm needs to work harder. It first \nneeds to accelerate in the right direction, and then as it gets near its \ntarget it needs to accelerate in the opposite direction, so its speed \ndecreases at precisely the correct rate to slow it to a stop at exactly \nthe right place.\nPATHFINDING\nGame characters usually need to move around their level. Sometimes \nthis movement is set in stone by the developers, such as a patrol \nroute that a guard can follow blindly or a small fenced region in \nwhich a dog can randomly wander around. Fixed routes are simple \nto implement, but can easily be fooled if an object is pushed in the \nway. Free wandering characters can appear aimless and can easily get \nstuck.\nMore complex characters don\u2019t know in advance where they\u2019ll \nneed to move.", "mimetype": "text/plain", "start_char_idx": 84478, "end_char_idx": 89033, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1db10de4-47e8-4e09-9673-cdae92e1bef0": {"__data__": {"id_": "1db10de4-47e8-4e09-9673-cdae92e1bef0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "61c5d146-fcdf-426d-bfc9-47199cab8524", "node_type": "1", "metadata": {}, "hash": "7937b796ae5ec68aa7d93370987fbffd946466e26c8460887469a2f51ac2a4f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "66ad281c-f01c-4fc1-8567-ce862e25003c", "node_type": "1", "metadata": {}, "hash": "81ec8bb6e75dc5f62650e28800a377e38b136e914bad12231b8696799eee0592", "class_name": "RelatedNodeInfo"}}, "text": "A dynamic movement algorithm needs to work harder. It first \nneeds to accelerate in the right direction, and then as it gets near its \ntarget it needs to accelerate in the opposite direction, so its speed \ndecreases at precisely the correct rate to slow it to a stop at exactly \nthe right place.\nPATHFINDING\nGame characters usually need to move around their level. Sometimes \nthis movement is set in stone by the developers, such as a patrol \nroute that a guard can follow blindly or a small fenced region in \nwhich a dog can randomly wander around. Fixed routes are simple \nto implement, but can easily be fooled if an object is pushed in the \nway. Free wandering characters can appear aimless and can easily get \nstuck.\nMore complex characters don\u2019t know in advance where they\u2019ll \nneed to move. A unit in a real-time strategy game may be ordered to \nany point on the map by the player at any time, a patrolling guard \nin a stealth game may need to move to its nearest alarm point to call \nfor reinforcements, and a platform game may require opponents to \nchase the player across a chasm using available platforms.\nFor each of these characters, the AI must be able to calculate a \nsuitable route through the game level to get from where it is now \nto its goal. We\u2019d like the route to be sensible and as short or rapid \nas possible (it doesn\u2019t look smart if your character walks from the \nkitchen to the lounge via the attic).\nThis is pathfinding, sometimes called path planning, and it is \neverywhere in game AI.\n\nTECHNIQUES\u2002 \u200951\nIn our model of game AI (Figure 5.3), pathfinding sits on the bor-\nder between decision-making and movement. Often, it is used sim-\nply to work out where to move to reach a goal; the goal is decided \nby another bit of AI, and the pathfinder simply works out how to get \nthere. To accomplish this, it can be embedded in a movement control \nsystem so that it is only called when it is needed to plan a route. But \npathfinding can also be placed in the driving seat, making decisions \nabout where to move as well as how to get there.\nThe vast majority of games use pathfinding solutions based on an \nalgorithm called A*. Although it\u2019s efficient and easy to implement, \nA* can\u2019t work directly with the game level data. It requires that the \ngame level be represented in a particular data structure: a directed \nnonnegative weighted graph.\nDECISION-MAKING\nAsk a gamer about game AI, and they think about decision-making: \nthe ability of a character to decide what to do. Carrying out that \ndecision (movement, animation, and the like) is taken for granted.\nFigure 5.3 The AI model.\n\n52\u2002 \u2009TECHNIQUES\nIn reality, decision-making is typically a small part of the effort \nneeded to build great game AI. Most games use simple decision-mak-\ning systems: state machines and behavior trees. Rule-based systems \nare rarer, but important.\nIn recent years, a lot of interest has been shown in more sophis-\nticated decision-making tools, such as fuzzy logic and neural net-\nworks. Despite notable uses in some high-profile games (often \naccompanied by much marketing fanfare), developers haven\u2019t been \nin a rush to embrace these technologies. It can be hard to get them \nworking right. Decision-making is the middle component of our AI \nmodel (Figure 5.4).\nOVERVIEW OF DECISION-MAKING\nAlthough there are many different decision-making techniques, we \ncan look at them all as acting in the same way.\nThe character processes a set of information that it uses to generate \nan action that it wants to carry out. The input to the decision-making \nsystem is the knowledge that a character possesses, and the output is \nFigure 5.4 The AI model.\n\nTECHNIQUES\u2002 \u200953\nan action request. The knowledge can be further broken down into \nexternal and internal knowledge. External knowledge is the infor-\nmation that a character knows about the game environment around \nit: the position of other characters, the layout of the level, whether a \nswitch has been thrown, the direction that a noise is coming from, \nand so on. Internal knowledge is information about the character\u2019s \ninternal state or thought processes: its health, its ultimate goals, what \nit was doing a couple of seconds ago, and so on.\nTypically, the same knowledge can drive any of the algorithms \nin this chapter.", "mimetype": "text/plain", "start_char_idx": 88237, "end_char_idx": 92516, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "66ad281c-f01c-4fc1-8567-ce862e25003c": {"__data__": {"id_": "66ad281c-f01c-4fc1-8567-ce862e25003c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1db10de4-47e8-4e09-9673-cdae92e1bef0", "node_type": "1", "metadata": {}, "hash": "4a3bce66cc2c3d2ddc8c66b657b65a06bc672ee49c103514b1300407c02548ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aaeb43bc-6f0c-41c2-a6cb-395dd843e10f", "node_type": "1", "metadata": {}, "hash": "b4b2cc695b151fedc9987db1691a40da5f607fb1917c3b8869f2f7c0ddb2c09d", "class_name": "RelatedNodeInfo"}}, "text": "The character processes a set of information that it uses to generate \nan action that it wants to carry out. The input to the decision-making \nsystem is the knowledge that a character possesses, and the output is \nFigure 5.4 The AI model.\n\nTECHNIQUES\u2002 \u200953\nan action request. The knowledge can be further broken down into \nexternal and internal knowledge. External knowledge is the infor-\nmation that a character knows about the game environment around \nit: the position of other characters, the layout of the level, whether a \nswitch has been thrown, the direction that a noise is coming from, \nand so on. Internal knowledge is information about the character\u2019s \ninternal state or thought processes: its health, its ultimate goals, what \nit was doing a couple of seconds ago, and so on.\nTypically, the same knowledge can drive any of the algorithms \nin this chapter. Some internal data are particular to the algorithms \nthemselves (a state machine needs to hold what state the character \nis currently in, for example, where a goal-oriented behavior needs \nto know what its current goal is). The algorithms themselves control \nwhat kinds of internal knowledge can be used (whether it stores \ngoals, states, plans, or probabilities), although they don\u2019t constrain \nwhat that knowledge represents, in game terms.\nThe behavior of an algorithm, correspondingly, can affect the \ngame in two ways: They can request an action that will change the \nexternal state of the character (such as throwing a switch, firing a \nweapon, and moving into a room), and they can change the internal \nstate of the algorithm (such as adopting a new goal, or adjusting a \nprobability). See Figure 5.5 for a schematic representation of this.\nChanges to the internal state are, by definition, less visible to the \nplayer, in the same way that changes in a person\u2019s mental state are not \nvisible unless they act on them. But in most decision-making algo-\nrithms, the internal state is where most of the work is done. Changes \nmight correspond to altering the character\u2019s opinion of the player, \nchanging its emotional state, or adopting a new goal. Again, algo-\nrithms will typically carry out those internal changes in a way that is \nparticular to the algorithm, while external actions can be generated \nin a form that is identical for each algorithm.\nThe format and quantity of the knowledge available to the AI \ndepend on the requirements of the game. Knowledge representation \nis intrinsically linked with most decision-making algorithms. It is \ndifficult to be completely general with knowledge representation.\n\n54\u2002 \u2009TECHNIQUES\nTACTICAL AND STRATEGIC AI\nThe decision-making techniques we looked at in the last chapter \nhave two important limitations: They are intended for use by a single \ncharacter, and they don\u2019t try to infer from the knowledge they have \nto a prediction of the whole situation.\nEach of these limitations is broadly in the category of tactics and \nstrategy. This chapter looks at techniques that provide a framework \nfor tactical and strategic reasoning in characters. It includes methods \nto deduce the tactical situation from sketchy information, to use the \ntactical situation to make decisions, and to coordinate between mul-\ntiple characters.\nIn the model of AI I\u2019ve been using so far, this provides the third \nlayer of our system, as shown in Figure 5.6.\nIt is worth remembering again that not all parts of the model \nare needed in every game. Tactical and strategic AI, in particular, is \nsimply not needed in many game genres. Where players expect to \nsee predictable behavior (in a two-dimensional [2D] shooter or a \nplatform game, for example), it may simply frustrate them to face \nmore complex behaviors.\nFigure 5.5 Decision-making schematic.\n\nTECHNIQUES\u2002 \u200955\nThere has been a rapid increase in the tactical capabilities of \nAI-controlled characters over the last 10 years, partly because of the \nincrease in AI budgets and processor speeds, and partly due to the \nadoption of simple techniques that can bring impressive results, as \nwe\u2019ll see in this chapter. It is an exciting and important area to be \nworking in, and there is no sign of that changing.\nLEARNING\nMachine learning (often abbreviated ML, though in this book I will \nsimply call it \u201clearning\u201d) is a hot topic in technology and business, \nand that excitement has filtered into games. In principle, learning \nAI has the potential to adapt to each player, learning their tricks and \ntechniques and providing a consistent challenge. It has the poten-\ntial to produce more believable characters: characters that can learn \nabout their environment and use it to the best effect.", "mimetype": "text/plain", "start_char_idx": 91650, "end_char_idx": 96296, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aaeb43bc-6f0c-41c2-a6cb-395dd843e10f": {"__data__": {"id_": "aaeb43bc-6f0c-41c2-a6cb-395dd843e10f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "66ad281c-f01c-4fc1-8567-ce862e25003c", "node_type": "1", "metadata": {}, "hash": "81ec8bb6e75dc5f62650e28800a377e38b136e914bad12231b8696799eee0592", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ebfed5d0-b61d-43c3-90a1-f8e1c6b04e42", "node_type": "1", "metadata": {}, "hash": "7361d3f8cb57f49821b6a0aefa47abb17967c955f8d671f4cdfeef59acaa65b3", "class_name": "RelatedNodeInfo"}}, "text": "TECHNIQUES\u2002 \u200955\nThere has been a rapid increase in the tactical capabilities of \nAI-controlled characters over the last 10 years, partly because of the \nincrease in AI budgets and processor speeds, and partly due to the \nadoption of simple techniques that can bring impressive results, as \nwe\u2019ll see in this chapter. It is an exciting and important area to be \nworking in, and there is no sign of that changing.\nLEARNING\nMachine learning (often abbreviated ML, though in this book I will \nsimply call it \u201clearning\u201d) is a hot topic in technology and business, \nand that excitement has filtered into games. In principle, learning \nAI has the potential to adapt to each player, learning their tricks and \ntechniques and providing a consistent challenge. It has the poten-\ntial to produce more believable characters: characters that can learn \nabout their environment and use it to the best effect. It also has the \npotential to reduce the effort needed to create game-specific AI: \nFigure 5.6 The AI model.\n\n56\u2002 \u2009TECHNIQUES\nCharacters should be able to learn about their surroundings and the \ntactical options that they provide.\nIn practice, it hasn\u2019t yet fulfilled its promise, and not for want \nof trying. Applying learning to your game requires careful planning \nand an understanding of the pitfalls. There have been some impres-\nsive successes in building learning AI that learns to play games, but \nless in providing compelling characters or enemies. The potential is \nsometimes more attractive than the reality, but if you understand \nthe quirks of each technique and are realistic about how you apply \nthem, there is no reason why you can\u2019t take advantage of learning in \nyour game.\nThere is a whole range of different learning techniques, from \nvery simple number tweaking through to complex neural networks. \nWhile most of the attention in the last few years has been focused on \n\u201cdeep learning\u201d (a form of neural networks), there are many other \npractical approaches. Each has its own idiosyncrasies that need to be \nunderstood before they can be used in real games.\nLEARNING BASICS\nWe can classify learning techniques into several groups depending \non when the learning occurs, what is being learned, and what effects \nthe learning has on a character\u2019s behavior.\nONLINE OR OFFLINE LEARNING\nLearning can be performed during the game, while the player is \nplaying. This is online learning, and it allows the characters to adapt \ndynamically to the player\u2019s style and provides more consistent chal-\nlenges. As a player plays more, their characteristic traits can be better \nanticipated by the computer, and the behavior of characters can be \ntuned to playing styles. This might be used to make enemies pose an \nongoing challenge, or it could be used to offer the player more story \nlines of the kind they enjoy playing.\nUnfortunately, online learning also produces problems with pre-\ndictability and testing. If the game is constantly changing, it can be \n\nTECHNIQUES\u2002 \u200957\ndifficult to replicate bugs and problems. If an enemy character decides \nthat the best way to tackle the player is to run into a wall, then it can \nbe a nightmare to replicate the behavior (at worst you\u2019d have to play \nthrough the whole same sequence of games, doing exactly the same \nthing each time as the player).\nThe majority of learning in game AI is done offline, either \nbetween levels of the game or more often at the development studio \nbefore the game leaves the building. This is performed by processing \ndata about real games and trying to calculate strategies or parameters \nfrom them.\nThis allows more unpredictable learning algorithms to be tried \nout and their results to be tested exhaustively. The learning algorithms \nin games are usually applied offline; it is rare to find games that use \nany kind of online learning. Learning algorithms are increasingly \nbeing used offline to learn tactical features of multi-player maps, to \nproduce accurate pathfinding and movement data, and to bootstrap \ninteraction with physics engines. These are very constrained appli-\ncations. Studios are experimenting with using deep learning in a \nbroader way, having characters learn higher behavior from scratch. It \nremains to be seen whether this is successful enough to make major \ninroads into the way AI is created.\nApplying learning in the pause when loading the next level of \nthe game is a kind of offline learning: Characters aren\u2019t learning as \nthey are acting. But it has many of the same downsides as online \nlearning. We need to keep it short (load times for levels are usually \npart of a publisher or console manufacturer\u2019s acceptance criteria for \na game and certainly affects player satisfaction).", "mimetype": "text/plain", "start_char_idx": 95402, "end_char_idx": 100096, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ebfed5d0-b61d-43c3-90a1-f8e1c6b04e42": {"__data__": {"id_": "ebfed5d0-b61d-43c3-90a1-f8e1c6b04e42", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aaeb43bc-6f0c-41c2-a6cb-395dd843e10f", "node_type": "1", "metadata": {}, "hash": "b4b2cc695b151fedc9987db1691a40da5f607fb1917c3b8869f2f7c0ddb2c09d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fbc0d088-eba8-41a2-8fd9-a8602ded00d9", "node_type": "1", "metadata": {}, "hash": "1f0498724b640b5074b6014b2ffac2c3f4b2fd752894211afd4de09fa1d49b4c", "class_name": "RelatedNodeInfo"}}, "text": "Learning algorithms are increasingly \nbeing used offline to learn tactical features of multi-player maps, to \nproduce accurate pathfinding and movement data, and to bootstrap \ninteraction with physics engines. These are very constrained appli-\ncations. Studios are experimenting with using deep learning in a \nbroader way, having characters learn higher behavior from scratch. It \nremains to be seen whether this is successful enough to make major \ninroads into the way AI is created.\nApplying learning in the pause when loading the next level of \nthe game is a kind of offline learning: Characters aren\u2019t learning as \nthey are acting. But it has many of the same downsides as online \nlearning. We need to keep it short (load times for levels are usually \npart of a publisher or console manufacturer\u2019s acceptance criteria for \na game and certainly affects player satisfaction). We need to take care \nthat bugs and problems can be replicated without replaying tens of \ngames. We need to make sure that the data from the game are easily \navailable in a suitable format (we can\u2019t use long post-processing steps \nto dig data out of a huge log file, for example).\nMost of the techniques in this chapter can be applied either online \nor offline. They aren\u2019t limited to one or the other. If they are to be \napplied online, then the data they will learn from are presented as \nthey are generated by the game. If it is used offline, then the data are \nstored and pulled in as a whole later.\n\n58\u2002 \u2009TECHNIQUES\nINTRA-BEHAVIOR LEARNING\nThe simplest kinds of learning are those that change a small area of \na character\u2019s behavior. They don\u2019t change the whole quality of the \nbehavior, but simply tweak it a little. These intra-behavior learning \ntechniques are easy to control and can be easy to test.\nExamples include learning to target correctly when projectiles are \nmodeled by accurate physics, learning the best patrol routes around a \nlevel, learning where cover points are in a room, and learning how to \nchase an evading character successfully. Most of the learning exam-\nples in this chapter will illustrate intra-behavior learning.\nAn intra-behavior learning algorithm doesn\u2019t help a character \nwork out that it needs to do something very different (if a character \nis trying to reach a high ledge by learning to run and jump, it won\u2019t \ntell the character to simply use the stairs instead, for example).\nINTER-BEHAVIOR LEARNING\nThe frontier for learning AI in games is learning of behavior. What \nI mean by behavior is a qualitatively different mode of action\u2014for \nexample, a character that learns the best way to kill an enemy is to \nlay an ambush or a character that learns to tie a rope across a back-\nstreet to stop an escaping motorbiker. Characters that can learn from \nscratch how to act in the game provide a challenging opposition for \neven the best human players.\nUnfortunately, this kind of AI is on the limit of what might be \npossible.\nOver time, an increasing amount of character behavior may be \nlearned, either online or offline. Some of this may be to learn how to \nchoose between a range of different behaviors (although the atomic \nbehaviors will still need to be implemented by the developer). It is \ndoubtful that it will be economical to learn everything. The basic \nmovement systems, decision-making tools, suites of available behav-\niors, and high-level decision-making will almost certainly be easier \nand faster to implement directly. They can then be augmented with \nintra-behavior learning to tweak parameters.\n\nTECHNIQUES\u2002 \u200959\nThe frontier for learning AI is decision-making. Developers are \nincreasingly experimenting with replacing AI techniques with learn-\ning systems, in particular deep learning.\nA WARNING\nIn reality, learning is not as widely used as you might think. Some \nof this is due to the relative complexity of learning techniques (in \ncomparison with pathfinding and movement algorithms, at least). \nBut games developers master far more complex techniques all the \ntime, for graphics, network, and physics simulation. The biggest \nproblems with learning are not difficulty, but reproducibility and \nquality control.\nImagine a game in which the enemy characters learn their envi-\nronment and the player\u2019s actions over the course of several hours of \ngameplay. While playing one level, the QA team notices that a group \nof enemies is stuck in one cavern, not moving around the whole \nmap. It is possible that this condition occurs only as a result of the \nparticular set of things they have learned. In this case, finding the \nbug and later testing if it has been fixed involves replaying the same \nlearning experiences.", "mimetype": "text/plain", "start_char_idx": 99219, "end_char_idx": 103878, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fbc0d088-eba8-41a2-8fd9-a8602ded00d9": {"__data__": {"id_": "fbc0d088-eba8-41a2-8fd9-a8602ded00d9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ebfed5d0-b61d-43c3-90a1-f8e1c6b04e42", "node_type": "1", "metadata": {}, "hash": "7361d3f8cb57f49821b6a0aefa47abb17967c955f8d671f4cdfeef59acaa65b3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c09d6d55-9a1e-4dc0-8851-4e1f269cc3fc", "node_type": "1", "metadata": {}, "hash": "64cdfd72e52c3e65521276b032cc09301044402c2352453ca42a0165b1fe6888", "class_name": "RelatedNodeInfo"}}, "text": "A WARNING\nIn reality, learning is not as widely used as you might think. Some \nof this is due to the relative complexity of learning techniques (in \ncomparison with pathfinding and movement algorithms, at least). \nBut games developers master far more complex techniques all the \ntime, for graphics, network, and physics simulation. The biggest \nproblems with learning are not difficulty, but reproducibility and \nquality control.\nImagine a game in which the enemy characters learn their envi-\nronment and the player\u2019s actions over the course of several hours of \ngameplay. While playing one level, the QA team notices that a group \nof enemies is stuck in one cavern, not moving around the whole \nmap. It is possible that this condition occurs only as a result of the \nparticular set of things they have learned. In this case, finding the \nbug and later testing if it has been fixed involves replaying the same \nlearning experiences. This is often impossible.\nIt is this kind of unpredictability that is the most often cited rea-\nson for severely curbing the learning ability of game characters. As \ncompanies developing industrial learning AI have often found, it is \nimpossible to avoid the AI learning the \u201cwrong\u201d thing.\nWhen you read academic papers about learning and games, they \noften use dramatic scenarios to illustrate the potential of a learning \ncharacter on gameplay. You need to ask yourself, if the character can \nlearn such dramatic changes of behavior, then can it also learn dra-\nmatically poor behavior: behavior that might fulfill its own goals \nbut will produce terrible gameplay? You can\u2019t have your cake and eat \nit. The more flexible your learning is, the less control you have on \ngameplay.\nThe normal solution to this problem is to constrain the kinds of \nthings that can be learned in a game. It is sensible to limit a particular \n\n60\u2002 \u2009TECHNIQUES\nlearning system to working out places to take cover, for example. \nThis learning system can then be tested by making sure that the cover \npoints it is identifying look right. The learning will have difficulty \ngetting carried away; it has a single task that can be easily visualized \nand checked.\nUnder this modular approach, there is nothing to stop several \ndifferent learning systems from being applied (one for cover points, \nanother to learn accurate targeting, and so on). Care must be taken \nto ensure that they can\u2019t interact in nasty ways. The targeting AI may \nlearn to shoot in such a way that it often accidentally hits the cover \nthat the cover-learning AI is selecting, for example.\nOVER-LEARNING\nA common problem identified in much of the AI learning litera-\nture is over-fitting, or over-learning. This means that if a learning \nAI is exposed to a number of experiences and learns from them, it \nmay learn the response to only those situations. We normally want \nthe learning AI to be able to generalize from the limited number \nof experiences it has to be able to cope with a wide range of new \nsituations.\nDifferent algorithms have different susceptibilities to over-fitting. \nNeural networks particularly can over-fit during learning if they are \nwrongly parameterized or if the network is too large for the learning \ntask at hand. We\u2019ll return to these issues as we consider each learning \nalgorithm in turn.\nTHE BALANCE OF EFFORT\nThe key thing to remember in all learning algorithms is the balance \nof effort. Learning algorithms are attractive because you can do less \nimplementation work. You don\u2019t need to anticipate every eventual-\nity or make the character AI particularly good. Instead, you create a \ngeneral-purpose learning tool and allow that to find the really tricky \nsolutions to the problem. The balance of effort should be that it is \n\nTECHNIQUES\u2002 \u200961\nless work to get the same result by creating a learning algorithm to \ndo some of the work.\nUnfortunately, it is often not possible. Learning algorithms can \nrequire a lot of hand-holding: presenting data in the correct way, \nparameterizing the learning system, making sure their results are \nvalid, and testing them to avoid them learning the wrong thing.\nI advise developers to consider carefully the balance of effort \ninvolved in learning. If a technique is very tricky for a human being \nto solve and implement, then it is likely to be tricky for the com-\nputer, too. If a human being can\u2019t reliably learn to keep a car cor-\nnering on the limit of its tire\u2019s grip, then a computer is unlikely to \nsuddenly find it easy when equipped with a vanilla learning algo-\nrithm. To get the result, you likely have to do a lot of additional work.", "mimetype": "text/plain", "start_char_idx": 102946, "end_char_idx": 107547, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c09d6d55-9a1e-4dc0-8851-4e1f269cc3fc": {"__data__": {"id_": "c09d6d55-9a1e-4dc0-8851-4e1f269cc3fc", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fbc0d088-eba8-41a2-8fd9-a8602ded00d9", "node_type": "1", "metadata": {}, "hash": "1f0498724b640b5074b6014b2ffac2c3f4b2fd752894211afd4de09fa1d49b4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e7e43395-7990-4142-80b8-dcf895a2bbfe", "node_type": "1", "metadata": {}, "hash": "74887e3b062cf94dda4d5852021e105aa16044a1ed55089ddbe3e2fd32b42d4a", "class_name": "RelatedNodeInfo"}}, "text": "Unfortunately, it is often not possible. Learning algorithms can \nrequire a lot of hand-holding: presenting data in the correct way, \nparameterizing the learning system, making sure their results are \nvalid, and testing them to avoid them learning the wrong thing.\nI advise developers to consider carefully the balance of effort \ninvolved in learning. If a technique is very tricky for a human being \nto solve and implement, then it is likely to be tricky for the com-\nputer, too. If a human being can\u2019t reliably learn to keep a car cor-\nnering on the limit of its tire\u2019s grip, then a computer is unlikely to \nsuddenly find it easy when equipped with a vanilla learning algo-\nrithm. To get the result, you likely have to do a lot of additional work. \nGreat results in academic papers can be achieved by the researchers \ncarefully selecting the problem they need to solve, and spending a \nlot of time fine-tuning the solution. Both are luxuries a studio AI \ndeveloper cannot afford.\nPROCEDURAL CONTENT GENERATION\nProcedural content generation is a hot topic in game development. \nBut it is not new. Its use goes back to the 8-bit era of the 1980s. Both \nElite and Exile generated a sizable portion of their content (in the first \ncase a whole galaxy of stars; in the second an underground cave sys-\ntem). Both games were the same each time you played, but the game \ncontent was far too big to fit in the 32 kB of RAM available. They used \nprocedural generation as a form of compression. Elite in particular \nproved highly influential, directly leading to games such as Spore, Elite: \nDangerous, and No Man\u2019s Sky.\nIn the early 1980s, Rogue was first released as freeware for main-\nframe machines. It featured a procedurally generated dungeon that \nwas different on each play, and permadeath so a level couldn\u2019t be \nrepeated over and over until it was beaten. Rogue led to many other \nnoncommercial and hobbyist games, often using similar pure text \ninterfaces. The genre became known as Rogue-likes. Procedural \n\n62\u2002 \u2009TECHNIQUES\ncontent generation and permadeath crossed into independent com-\nmercial games, becoming a phenomenon with titles such as The Bind-\ning of Isaac and Spelunky, a burgeoning genre that came to be known \nas Rogue-lites. Procedural dungeon generation even featured in AAA \ntitles such as Diablo and the chalice dungeons of Bloodborne.\nSpore also draws on another thread of procedural content gener-\nation: the demo scene. Participants compete to produce the most \nspectacular audio and visual show, often based on highly constrained \nprogram sizes. This is often a combination of both shaving the size of \nan executable with hand-optimized assembly code, and generating \nthe audio and much of the visuals with procedural content gener-\nation. Will Wright, the creator of Spore, recruited prominent demo \nscene coders to work on that game.\nStrategy games such as Civilization, and its sequels, use procedural \nlevel generation to create varied maps for multi-player games. Land-\nscape generation is ubiquitous enough that most game artists use \nsome kind of content generation\u2014possibly with human modifica-\ntion\u2014to create terrain, even in games with fixed levels. This is pro-\ncedural content generation used in the studio, rather than running \non the game machine. Minecraft brought landscape and world genera-\ntion to a huge audience. Building on a simple block-based structure, \nMojang over time has added generation routines to create mines, \nvillages, temples, and other structures, each intended to evoke the \nfeel of something man-made.\nAnd finally, in a survey of games, it would be remiss not to give \ndue credit to Dwarf Fortress, in some ways a game that owes a lot to \nRogue, particularly in its aesthetics, but where procedural content \ngeneration has been pushed into all systems. The world is generated, \nas are dungeons, characters, back stories, civilizations, even legends, \nand artifacts. A book in this series contains procedural content gen-\neration advice, co-edited by the co-author of Dwarf Fortress.\nThis survey of procedural content generation illustrates its two \nmain uses: in game, to generate variety; and during development, to \nmake game assets higher fidelity or cheaper to create. In both cases, \nit replaces the work that would otherwise be done by a designer \n\nTECHNIQUES\u2002 \u200963\nor an artist. It is, therefore, an AI task. And unsurprisingly, it uses \ntechniques similar to those already covered in this book. In some \ncases, the connection can be more tenuous.", "mimetype": "text/plain", "start_char_idx": 106798, "end_char_idx": 111314, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e7e43395-7990-4142-80b8-dcf895a2bbfe": {"__data__": {"id_": "e7e43395-7990-4142-80b8-dcf895a2bbfe", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c09d6d55-9a1e-4dc0-8851-4e1f269cc3fc", "node_type": "1", "metadata": {}, "hash": "64cdfd72e52c3e65521276b032cc09301044402c2352453ca42a0165b1fe6888", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0c58bb55-3dd2-47d0-95a2-f7d3b9506520", "node_type": "1", "metadata": {}, "hash": "06cec37098cdbdd95520446ab57d00dd539beb7bca30e8805192188bec63de33", "class_name": "RelatedNodeInfo"}}, "text": "The world is generated, \nas are dungeons, characters, back stories, civilizations, even legends, \nand artifacts. A book in this series contains procedural content gen-\neration advice, co-edited by the co-author of Dwarf Fortress.\nThis survey of procedural content generation illustrates its two \nmain uses: in game, to generate variety; and during development, to \nmake game assets higher fidelity or cheaper to create. In both cases, \nit replaces the work that would otherwise be done by a designer \n\nTECHNIQUES\u2002 \u200963\nor an artist. It is, therefore, an AI task. And unsurprisingly, it uses \ntechniques similar to those already covered in this book. In some \ncases, the connection can be more tenuous. Similarly, game textures \nare often procedurally generated, but methods for achieving this are \nbased on image filtering and graphical programming techniques. At \nthe other extreme, games such as Left 4 Dead and Earthfall generate \ngameplay moments using a \u201cdirector\u201d AI: decision-making that anal-\nyses the state of the game and schedules new enemies and encoun-\nters to keep it interesting and challenging to the player.\nBOARD GAMES\nThe earliest application of AI to computer games was as opponents \nin simulated versions of common board games. In the West, Chess is \nthe archetypal board game, and the last 40 years have seen a dramatic \nincrease in the capabilities of Chess-playing computers.\nIn the same time frame, other games such as Tic-Tac-Toe, Connect \nFour, Reversi (Othello), and Go have been studied, in each case cul-\nminating in AI that can beat the best human opponents.\nThe AI techniques needed to make a computer play board games \nare very different. For the real-time games that dominate the charts, \nthis kind of AI only has limited applicability. It is occasionally used as \na strategic layer, making long-term decisions in war games, but even \nthen only when the game has been designed to be somewhat board \ngame like.\nThe best AI opponents for Go, Chess, Draughts, Backgammon, \nand Reversi\u2014those capable of beating the best human players\u2014have \nall used dedicated hardware, algorithms, or optimizations devised \nspecifically for the nuances of their strategy. This may be changing. \nWith the advent of deep learning board game AI, particularly those \ncreated by the company DeepMind, there is some indication that \nelite-level approaches can be applied to multiple games. As of writ-\ning, it remains to be seen whether the success can be replicated by \nothers, or whether even better results can be achieved by further \nspecialization.\n\n64\u2002 \u2009TECHNIQUES\nFor all these games, however, the basic underlying algorithms are \nshared in common, and can find application in any board game. The \nminimax family of algorithms is the most popular board game AI \ntechniques. A different family of algorithms has proven to be supe-\nrior in many applications: the memory-enhanced test driver (MTD) \nalgorithms. Both minimax and MTD are tree-search algorithms: They \nrequire a special tree representation of the game.\nThese algorithms are perfect for implementing the AI in board \ngames, but both rely on some knowledge of the game. The algo-\nrithms are designed to search for the best move to make, but the \ncomputer can\u2019t intuit what \u201cbest\u201d means; it needs to be told. At its \nsimplest, this can be just \u201cthe best move wins the game,\u201d which is \nall we need for a game like Tic-Tac-Toe, where minimax or MTD can \nsearch every possible sequence of moves. But for most games, there \nisn\u2019t enough computer power to search all the way to the end of the \ngame, so some knowledge about intermediate states is needed: The \nbest moves lead to the best positions, so how do we determine how \ngood a position is? We use a \u201cstatic evaluation function.\u201d\nThis is the same trade-off I introduced as the \u201cgolden rule of AI,\u201d \nwhen discussing symbolic AI in Chapter 1: The more search we can \ndo, the less knowledge we need, and vice versa. In the case of rea-\nsonably complicated board games, the amount of search we can do \nis limited by the computer power available; better search algorithms \nonly buy us a little. So the quality of the AI will depend more on the \nquality of the static evaluation function.\n\nDOI: 10.1201/9781003124047-7\n6\nSUPPORTING TECHNOLOGIES\nEXECUTION MANAGEMENT\nThere are only limited processor resources available to a game.", "mimetype": "text/plain", "start_char_idx": 110614, "end_char_idx": 114959, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0c58bb55-3dd2-47d0-95a2-f7d3b9506520": {"__data__": {"id_": "0c58bb55-3dd2-47d0-95a2-f7d3b9506520", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e7e43395-7990-4142-80b8-dcf895a2bbfe", "node_type": "1", "metadata": {}, "hash": "74887e3b062cf94dda4d5852021e105aa16044a1ed55089ddbe3e2fd32b42d4a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "238d01c6-3743-413b-a08e-cda027116527", "node_type": "1", "metadata": {}, "hash": "cf69c375402c20e860818b9b174a562d45ff66be518f6b36c40ea6e4eeab60e0", "class_name": "RelatedNodeInfo"}}, "text": "We use a \u201cstatic evaluation function.\u201d\nThis is the same trade-off I introduced as the \u201cgolden rule of AI,\u201d \nwhen discussing symbolic AI in Chapter 1: The more search we can \ndo, the less knowledge we need, and vice versa. In the case of rea-\nsonably complicated board games, the amount of search we can do \nis limited by the computer power available; better search algorithms \nonly buy us a little. So the quality of the AI will depend more on the \nquality of the static evaluation function.\n\nDOI: 10.1201/9781003124047-7\n6\nSUPPORTING TECHNOLOGIES\nEXECUTION MANAGEMENT\nThere are only limited processor resources available to a game. Tra-\nditionally, most of these have been used to create great graphics: \nthe primary driving force in mass-market games. Much of the hard \ngraphical processing is now performed on the GPU, but not all of it. \nFaster CPUs have also allowed the processor budget given to AI devel-\nopers to grow steadily, meaning that techniques too costly at one \ntime can now be implemented on even modest mobile hardware. \nIt is not unheard of for AI to have more than 50% of the processor \ntime, although 5%\u201325% is a more common range.\nEven with more execution time available, processor time can easily \nget eaten up by pathfinding, complex decision-making, and tactical \nanalysis. AI is also inherently inconsistent. Sometimes you need lots of \ntime to make a decision (planning a route, for example), and some-\ntimes a tiny budget is enough (moving along the route). All your \ncharacters may need to pathfind at the same time, and then you may \nhave hundreds of frames where nothing much is happening to the AI.\nA good AI system needs facilities that can make the best use of the \nlimited processing time available. There are three main elements to \nthis: dividing up the execution time among the AI that needs it, hav-\ning algorithms that can work a bit at a time over several frames, and, \nwhen resources are scarce, giving preferential treatment to important \ncharacters.\n\n66\u2002 \u2009SUPPORTING TECHNOLOGIES\nThe solution is motivated by AI, and without complex AI it is \nrarely needed. But developers with a good AI scheduling system tend \nto use it for many other purposes, too. I have seen a range of appli-\ncations for the good scheduling infrastructure: incremental loading \nof new areas of the level, texture management, game logic, audio \nscheduling, and physics updates all controlled by scheduling systems \noriginally designed with AI in mind.\nWORLD INTERFACING\nOne of the most difficult things to get right as an AI developer is the \ninteraction between the AI and the game world.\nEach character needs to get the information they could feasibly \nknow or perceive from the game world at the right time in order for \nthem to act on it. In addition, some algorithms need to have infor-\nmation from the world represented in the correct way for them to \nprocess correctly.\nTo build a general-purpose AI system, we need to have some \ninfrastructure that makes it easy to get the right information to the \nright bits of AI code in the right format at the right time. With a spe-\ncial-purpose, single-game AI, there may be no dividing line between \nthe world interface and the AI code: If the AI needs some informa-\ntion, it can go and find it there and then. In an engine designed to \nsupport AI in multiple games, however, it is essential for stability \nand reusability to have a single central world interface system. Even \nwithin one game, it can dramatically assist debugging to have all the \ninformation flowing through a central hub, allowing it to be visual-\nized, logged, and inspected.\nTOOLS AND CONTENT CREATION\nProgramming makes up a relatively small amount of the effort in a \nmass-market game. Most of the development time goes into content \ncreation, making models, textures, environments, sounds, music, \nand animation\u2014everything from the concept art to the fine-tuning \nof the level.\n\nSUPPORTING TECHNOLOGIES\u2002 \u200967\nOver the last 15 years, developers have reduced the programming \neffort further by reusing technology on multiple titles, creating or \nlicensing a game engine on which several games can run. Adding a \ncomprehensive suite of AI to the engine is a natural extension.\nMost developers aren\u2019t content to stop there, however. Because the \neffort involved in content creation is so great, the content creation \nprocess also needs to be standardized, and the runtime tools need \nto be seamlessly integrated with development tools. For more than \na decade, these complete toolchains have been essential for develop-\nment of large games.", "mimetype": "text/plain", "start_char_idx": 114327, "end_char_idx": 118903, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "238d01c6-3743-413b-a08e-cda027116527": {"__data__": {"id_": "238d01c6-3743-413b-a08e-cda027116527", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0c58bb55-3dd2-47d0-95a2-f7d3b9506520", "node_type": "1", "metadata": {}, "hash": "06cec37098cdbdd95520446ab57d00dd539beb7bca30e8805192188bec63de33", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "824ca562-fd48-4ed8-8b0f-8ac15f8466ab", "node_type": "1", "metadata": {}, "hash": "e68dfc01daf445e6d22e188c62418048c11f9d4d0aa2df76e75640dfcb0cf6da", "class_name": "RelatedNodeInfo"}}, "text": "Most of the development time goes into content \ncreation, making models, textures, environments, sounds, music, \nand animation\u2014everything from the concept art to the fine-tuning \nof the level.\n\nSUPPORTING TECHNOLOGIES\u2002 \u200967\nOver the last 15 years, developers have reduced the programming \neffort further by reusing technology on multiple titles, creating or \nlicensing a game engine on which several games can run. Adding a \ncomprehensive suite of AI to the engine is a natural extension.\nMost developers aren\u2019t content to stop there, however. Because the \neffort involved in content creation is so great, the content creation \nprocess also needs to be standardized, and the runtime tools need \nto be seamlessly integrated with development tools. For more than \na decade, these complete toolchains have been essential for develop-\nment of large games. With the explosion in popularity of the Unity \nengine, they have become crucial to the existence of small studios, \nindependent developers, and hobbyists.\nIn fact, it is difficult to overstate the importance of the toolchain \nin modern game development. At the time of the first edition of \nthis book, the toolchain was seen as a major deciding factor in a \npublisher\u2019s decisions to back a project. Now it is almost ubiquitous. \nIt is a rare and brave developer indeed that creates a new game from \nscratch without a proven toolchain in place.\nPartly, this is due to their availability. RenderWare Studio was a \nmajor selling point for Criterion\u2019s graphics middleware in the early \n2000s. But licensing it was costly and required a detailed agree-\nment with a vendor. Now it is trivial to download Unity or Unreal \nEngine from the web, experiment under a simple end user license, \nand have access to a widely supported and powerful toolchain. These \ntools are not free, but their ease of use has transformed the industry. \nIn addition to these two market leaders, other systems such as the \nopen-source Godot and Amazon\u2019s Lumberyard (a fork of the Crytek\u2019s \nCryEngine) also emphasize the same style of game development, \nwith the toolchain and a custom editor application at the core.\nTOOLCHAINS LIMIT AI\nThe importance of toolchains places limits on the AI. Advanced \ntechniques such as neural networks, genetic algorithms, and \ngoal-oriented action planning (GOAP) haven\u2019t been widely used in \ncommercial titles. To some degree, this is because they are naturally \n\n68\u2002 \u2009SUPPORTING TECHNOLOGIES\ndifficult to map into a level editing tool. They require specific pro-\ngramming for a character, which limits the speed at which new lev-\nels can be created and the code reuse between projects.\nThe majority of AI-specific design tools are concerned with the \nbread-and-butter techniques: finite state machines or behavior trees, \nmovement, and pathfinding. These approaches rely on simple pro-\ncesses and significant knowledge. Toolchains are naturally better at \nallowing designers to modify data rather than code, so the use of \nthese classic techniques is being reinforced.\nWHERE AI KNOWLEDGE COMES FROM\nGood AI requires a lot of knowledge. Having good and appropriate \nknowledge about the game environment saves a huge amount of \nprocessing time. And at runtime, when the game has many things to \nkeep track of, processing time is a crucial resource.\nThe knowledge required by AI algorithms depends on the envi-\nronment of the game. A character moving around, for example, \nneeds some knowledge of where and how it is possible to move. \nThis can be provided by the programmers, giving the AI the data it \nneeds directly.\nWhen the game level changes, however, the programmer needs \nto provide new sets of data. This does not promote reuse between \nmultiple games and makes it difficult for simple changes to be made \nto levels. A toolchain approach to developing a game puts the onus \non the content creation team to provide the necessary AI knowledge. \nThis process can be aided by offline processing which automatically \nproduces a database of knowledge from the raw level information.\nFor years, it has been common for the content creation team to \nprovide the AI knowledge for movement and pathfinding, either \nexplicitly by marking up the level itself or by having such data gen-\nerated automatically from the content they create. More recently, \ndecision-making and higher-level AI functions have also been incor-\nporated into the toolchain, usually via custom tools integrated into \nthe editor application.", "mimetype": "text/plain", "start_char_idx": 118053, "end_char_idx": 122517, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "824ca562-fd48-4ed8-8b0f-8ac15f8466ab": {"__data__": {"id_": "824ca562-fd48-4ed8-8b0f-8ac15f8466ab", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "238d01c6-3743-413b-a08e-cda027116527", "node_type": "1", "metadata": {}, "hash": "cf69c375402c20e860818b9b174a562d45ff66be518f6b36c40ea6e4eeab60e0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b7e121c-8beb-4140-9196-4626e73d5365", "node_type": "1", "metadata": {}, "hash": "b0aaaf4dfd345e363cd0ca61820b325c379255074150c3f562826b1a8c486c2b", "class_name": "RelatedNodeInfo"}}, "text": "This can be provided by the programmers, giving the AI the data it \nneeds directly.\nWhen the game level changes, however, the programmer needs \nto provide new sets of data. This does not promote reuse between \nmultiple games and makes it difficult for simple changes to be made \nto levels. A toolchain approach to developing a game puts the onus \non the content creation team to provide the necessary AI knowledge. \nThis process can be aided by offline processing which automatically \nproduces a database of knowledge from the raw level information.\nFor years, it has been common for the content creation team to \nprovide the AI knowledge for movement and pathfinding, either \nexplicitly by marking up the level itself or by having such data gen-\nerated automatically from the content they create. More recently, \ndecision-making and higher-level AI functions have also been incor-\nporated into the toolchain, usually via custom tools integrated into \nthe editor application.\n\nSUPPORTING TECHNOLOGIES\u2002 \u200969\nPROGRAMMING GAME AI\nEditors and other tools are important for content creation: build-\ning the data that give the game its gameplay, from the obvious \nvisual design of the geometry of levels to the configuration of \nAI algorithms that make up character behavior. Different AI \napproaches will require different tools: extensions to level editing \nor 3D modeling, or custom tools for visualizing and configuring \ndecision-making. The exact requirement depends on the approach \nbeing used.\nIn contrast, there is one tool that is always necessary, so much so \nthat it can be easily ignored in a discussion of supporting technolo-\ngies. All AI is programmed. And the programming language has a big \nimpact on the design of the AI.\nPathfinding or decision trees, for example, are general approaches \nthat can be used in a whole range of games. These techniques need \nto be implemented. A decade ago, it would not be unreasonable to \nassume that they would be implemented in C++ as part of the core \ngame code. That has changed radically now. Although game engines \nare still usually implemented in C and C++, most of the AI is typ-\nically implemented in another language. The most common com-\nmercial game engines, Unity and Unreal Engine 4 (UE4), provide \na pathfinding system written in C++, but if you need any other AI \ntechnique (a behavior tree, for example, or steering behaviors), it \nneeds to be written, or licensed from a third party. In UE4, this may \nstill involve coding in C++, but in Unity, it probably means imple-\nmenting in C#. In both cases, the new code acts as a kind of plug-in, \non equal footing with gameplay code rather than core facilities such \nas networking and 3D rendering.\nAt the same time, mobile and online development has burgeoned, \nwhere implementation languages are constrained by the target plat-\nform: Swift (and before that Objective-C) on iOS, Java (or other \nJVM languages such as Kotlin) on Android, and JavaScript on the \nweb. Together, these trends have meant that AI techniques are being \nimplemented in a much broader range of languages.\n\n70\u2002 \u2009SUPPORTING TECHNOLOGIES\nBut general-purpose AI techniques are only one place in which \nAI code requires programming support. It is common to use small \nscripts written in an embedded programming language to control \ncharacter behavior. Often this is easier than using a general-purpose \ntechnique, and developing tools to configure it correctly. Provided \nthat the person creating the character behavior is reasonably con-\nfident with simple programming tasks, it might be much easier to \nproduce state-based behavior with a series of if-statements rather \nthan dragging blocks and transitions in a general purpose state \nmachine editor.\nCommercial game engines always provide some form of scripting \nsupport. If you are developing your tool set from scratch, you may \nneed to add your own. Although increasingly rare, many developers \nhave felt existing options are unsuitable, and developed their own \nscripting languages.", "mimetype": "text/plain", "start_char_idx": 121542, "end_char_idx": 125559, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b7e121c-8beb-4140-9196-4626e73d5365": {"__data__": {"id_": "1b7e121c-8beb-4140-9196-4626e73d5365", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "824ca562-fd48-4ed8-8b0f-8ac15f8466ab", "node_type": "1", "metadata": {}, "hash": "e68dfc01daf445e6d22e188c62418048c11f9d4d0aa2df76e75640dfcb0cf6da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "309cea40-21a3-4a5a-b96a-0379e499eafe", "node_type": "1", "metadata": {}, "hash": "54e6fcaf7756bbd0a9a8d5acbdc4178e731df80e54b25955dee47705e5b49ea4", "class_name": "RelatedNodeInfo"}}, "text": "70\u2002 \u2009SUPPORTING TECHNOLOGIES\nBut general-purpose AI techniques are only one place in which \nAI code requires programming support. It is common to use small \nscripts written in an embedded programming language to control \ncharacter behavior. Often this is easier than using a general-purpose \ntechnique, and developing tools to configure it correctly. Provided \nthat the person creating the character behavior is reasonably con-\nfident with simple programming tasks, it might be much easier to \nproduce state-based behavior with a series of if-statements rather \nthan dragging blocks and transitions in a general purpose state \nmachine editor.\nCommercial game engines always provide some form of scripting \nsupport. If you are developing your tool set from scratch, you may \nneed to add your own. Although increasingly rare, many developers \nhave felt existing options are unsuitable, and developed their own \nscripting languages.\n\nacademic AI\nearly days, before computers \n4\u20135\nnatural computing 6\u20137\nstatistical era 6\u20137\nsymbolic systems 5\u20136\naction-based three-dimensional \n(3D) games 14\nagent-based model 15\nAI engine\nAI schematic 44\u201345\nSCUMM engine 41\nstructure of 42\u201343\ntool concerns 44\nAI model 12, 42\nagent-based AI 15\ndecision-making 13\ninfrastructure 14\u201315\nmovement 12\u201313\nstrategy 14\nalgorithms\nbehavior of 53\ncharacter-by-character  \nbasis 11\nhacks and heuristics 30\nimplement and tune  \n17\u201318\nimplementation 20\nperformance  \ncharacteristics 18\npseudo-code 18\u201319\nrepresentations 19\u201320\nstep-by-step processes 17\naliasing failure 36\nallocation process 35\u201336\nAlphaGo Zero 7\nAndroid 39\nanimation technology 13, 47\napplication programming  \ninterfaces (APIs) 37\nINDEX\n\n72\u2002 \u2009Index\nartificial intelligence (AI)\nacademic AI 4\u20137\nbread-and-butter  \ntechniques 68\nearliest application 63\nexpert systems 6\ngame development 2\nknowledge-infused search 5\nlearning literature 60\nnavigation systems 7\nscheduling system 66\nsymbolic route-planning \nalgorithm 6\naugmented reality (AR) 40\u201341\n\u201cbare metal\u201d performance \n32\u201333\nBeneath a Steel Sky 9\nThe Binding of Isaac game 62\nBlack & White game 10, 23\nBlood and Laurels game 10\nBloodborne game 62\nBoolean \u201chealthy\u201d value 20\nbranch prediction 33\nbread-and-butter techniques 68\ncache level 36\ncharacters, game AI 55\u201359\nChris Kingsley of Rebellion 22\nCivilization game 62\ncompute-intensive search 7\nconsoles, game AI 38\u201339\ncontent creation process 66\u201367\ncriticism 26\ncross-platform development 39\ndata structures 17\ndecision-making system 13,  \n14, 47\ncharacter processes 52\nexternal knowledge 53\ninternal knowledge 53\noverview of 52\u201354\ndecision trees 69\ndeep learning 5, 7, 56\nDiablo game 62\nDwarf Fortress game 62\ndynamic movement 49\u201350\neating animation 13\nemotion animations 22, 27\nengineering trade-off 6\nexpert systems 5, 6\nexternal knowledge 53\nF.E.A.R.", "mimetype": "text/plain", "start_char_idx": 124630, "end_char_idx": 127420, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "309cea40-21a3-4a5a-b96a-0379e499eafe": {"__data__": {"id_": "309cea40-21a3-4a5a-b96a-0379e499eafe", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b7e121c-8beb-4140-9196-4626e73d5365", "node_type": "1", "metadata": {}, "hash": "b0aaaf4dfd345e363cd0ca61820b325c379255074150c3f562826b1a8c486c2b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "724c04e8-211f-404f-a53d-3e2eb512d990", "node_type": "1", "metadata": {}, "hash": "7637b34d06466fae5c1eb9c27aa833f19d3738c852c863ab906d87c8566e0435", "class_name": "RelatedNodeInfo"}}, "text": "game 9\nfeedback loop 24\nFull Spectrum Warrior game 10\nfunction table 34\ngame AI 8\nad hoc solutions 26\nallocation process 35\u201336\naugmented reality 40\u201341\ncache level 36\nchange behavior 25\u201326\ncomplexity fallacy 21\nconsoles 38\u201339\ngarbage collection 35\u201336\nhacks 26\u201328\nheuristics 26, 28\u201329\n\nIndex\u2002 \u200973\nlow-level concerns 32\u201333\nmemory concerns 34\nmobiles 39\u201340\nperception window 24\u201325\nplatform differences 37\nprocessor issues 31\u201332\nprogramming 69\u201370\npromising thing 30\nspeed and memory  \nconstraints 31\nstupid-looking behavior 21\nvirtual reality 40\u201341\ngame characters 50, 55\u201359\ngame development 1, 2, 20,  \n61, 67\ngames developers 4, 59\ngarbage collection 35\u201336\nGaussian processes 7\ngeneral-purpose AI  \nsystem 66\n\u201cgesture\u201d command 27\ngoal-oriented action planning \n(GOAP) 9, 28, 67\nGodot engine 34, 39, 67\nGolden Axe game 9\nGoldeneye 007 game 9\n\u201cgolden rule of AI\u201d 64\nGoogle\u2019s search technology 7\nGrand Theft Auto 3 game 15\ngraphical programming  \ntechniques 63\ngraphics code 32\nhacks 26\u201328\nHalf-Life game 10\nHalf-Life 2 game 13, 14\nHalo game 9\nhand-optimized assembly  \ncode 62\nHerdy Gerdy game 23\nheuristics 28\u201329\nimage filtering 63\nimplementation 20, 35\ninter-behavior learning  \nalgorithm 57\u201359\ninternal knowledge 53\nInternet 1\nintra-behavior learning  \nalgorithm 57\niOS devices 39\nkinematic movement 49\nknowledge-infused search 5\nknowledge representation 53\nThe Last of Us game 10\nlearning algorithms 57, 60\nlearning system 60\u201361\nLegend of Zelda game 13\nlower-specification  \nmachines 38\nlow-level concerns 32\u201333\nLumberyard engine 34, 67\nmachine learning (ML)\neffort balance 60\u201361\ninter-behavior learning \n57\u201359\nintra-behavior learning 57\n\n74\u2002 \u2009Index\nmachine learning (ML) (cont.)", "mimetype": "text/plain", "start_char_idx": 127421, "end_char_idx": 129099, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "724c04e8-211f-404f-a53d-3e2eb512d990": {"__data__": {"id_": "724c04e8-211f-404f-a53d-3e2eb512d990", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d29fc2b5-a79d-42f7-ae22-faeb559b1d1f", "node_type": "4", "metadata": {}, "hash": "e161309f2e5c1bd9a6eafb1afdd60496e148f2136717c6b6197fbe002e4dac6d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "309cea40-21a3-4a5a-b96a-0379e499eafe", "node_type": "1", "metadata": {}, "hash": "54e6fcaf7756bbd0a9a8d5acbdc4178e731df80e54b25955dee47705e5b49ea4", "class_name": "RelatedNodeInfo"}}, "text": "online/offline learning \n56\u201357\nover-learning 60\nwarning 59\u201360\nMagic Leap 40\nmainframe machines 61\nmassively multi-player online \ngames (MMOGs) 34\nmass-market game 66\nMedal of Honor game 14\nmemory 34\nallocation process 35\u201336\ncache level 36\ngarbage collection 35\u201336\nmemory layout 36\nstructure of 49\nmemory-enhanced test driver \n(MTD) 64\nMetal Gear Solid game 9\nMicrosoft 40\nMinecraft game 62\nminimum-specification  \nmachine 38\nmobiles, game AI 39\u201340\nmodifications 1\nmovement algorithms 12\u201313, \n14, 47\nbasics of 48\u201350\ndecision-making 51\u201352\npathfinding 50\u201351\nnatural computing 6\u20137\nnavigation systems 7\nNintendo Game Boy 22, 39\nnon-agent-based AI 15\nonline/offline learning 56\u201357\noptimizations 26, 33\nPac-Man game 8\u20139, 21\u201322, 25\nparallelism 33\npathfinding 28, 32, 35\u201336, 51, \n65, 69\nPC development target  \nconsoles 39\nperception 14\nperformance characteristics 18\nplatform, game AI 37\nPlayStation 2 hardware 22\nPlayStation Portable (PSP) 39\nPok\u00e9mon Go game 41\npolymorphism 34\nprocedural content generation \n61\u201363\nprogramming language 69\u201370\npseudo-code 18\u201319\ndefinition of 20\nQuake II game 27\nreal-time strategy (RTS) games \n9, 29, 32, 50\nreference counting 35\nRenderWare Studio 67\nrepresentations 19\u201320\nRogue game 61\nrole-playing games (RPGs) 10\nrule-based systems 52\nscripting languages 32\nSIMD (single instruction, multi-\nple data) 33\n\nIndex\u2002 \u200975\nThe Sims game 10, 12, 27\nSpace Invaders mold 8\nSpelunky game 62\nSplinter Cell game 12\nSpore game 62\nStar Wars Episode 1: Racer game 27\nstatic evaluation function 64\nstatistical algorithm 8\nSteam platform 40\nsteering behaviors 44, 49\nSuper Mario Sunshine game 12\nsupport-vector machines  \n(SVMs) 7\nsymbolic algorithms 8\nsymbolic route-planning  \nalgorithm 6\nsymbolic system 5\ntechnical requirements checklist \n(TRC) process 39\ntechniques\nboard games 63\u201364\ndecision-making 51\u201352\novervifew of 52\u201354\nexecution management \n65\u201366\nmachine learning 55\u201361\nmachine learning (ML)\neffort balance 60\u201361\ninter-behavior learning \n57\u201359\nintra-behavior learning 57\nonline/offline learning \n56\u201357\nover-learning 60\nwarning 59\u201360\nmovement algorithms\nbasics of 48\u201350\npathfinding 50\u201351\nprocedural content  \ngeneration 61\u201363\ntactical and strategic  \nAI 54\u201355\ntoolchains places limits \n67\u201368\ntools and content creation \n66\u201367\nworld interfacing 66\nThief: The Dark Project game 9\nTic-Tac-Toe game 64\ntoolchains places limits 67\u201368\nUnity engine 35, 67\nUnreal engine 34, 37, 67, 69\nvirtual function 34\nvirtual reality (VR) 40\u201341\n\u201cVirtual Theater\u201d AI system 9\nvoice recognition program 8\nWarhammer: Dark Omen game 9, 29\nWorld of WarCraft game 9\n\nREQUEST A FREE TRIAL\nsupport@taylorfrancis.com\nTaylor & Francis eBooks\nwww.taylorfrancis.com\nA single destination for eBooks from Taylor & Francis  \nwith increased functionality and an improved user \nexperience to meet the needs of our customers.\n90,000+ eBooks of award-winning academic content in \nHumanities, Social Science, Science, Technology, Engineering, \nand Medical written by a global network of editors and authors.\nTAYLOR & FRANCIS EBOOKS OFFERS:\nA streamlined  \nexperience for  \nour library  \ncustomers\nA single point  \nof discovery  \nfor all of our  \neBook content\nImproved  \nsearch and  \ndiscovery of  \ncontent at both  \nbook and  \nchapter level", "mimetype": "text/plain", "start_char_idx": 129100, "end_char_idx": 132321, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"d29fc2b5-a79d-42f7-ae22-faeb559b1d1f": {"node_ids": ["1f23d5d9-bee0-47c9-a55d-2a01305d8f67", "49552a96-8bf5-4b69-8854-17140d368488", "06596a16-70d5-48ff-a8fd-dba80008d8f9", "7951feb3-a8cf-43c0-8075-0fb1ac912ba4", "d3f97a2e-3131-4fe8-a2c7-651f03df1172", "ab823cd3-4040-4441-a24f-1a9a29f589aa", "45cf733c-69c0-470a-8c79-fa810359703e", "07c3f608-22a6-446e-b666-5e03ea359526", "33c6bf02-982f-4910-a426-54e2e05488a4", "8c6896c5-4a08-482a-99ba-28e93e228ed4", "626cd07d-d4ed-4743-877d-eb7136654ca7", "9cd4157f-d7b0-4480-82ae-e0320ee9117a", "eb6dc8b4-1032-4930-9b10-d06e1cf101e0", "5606b253-28f1-427f-ae7a-b56b8fce61ac", "cab15ee7-e476-40e7-9b35-494889f732ee", "1f4431ec-283e-4d4a-a00c-7c108a4ef9fb", "2adc2031-6d46-493a-9cd1-2a492cd385fe", "c21eceb4-6c56-4412-b88b-9ad691ca8c66", "35f900bb-ac69-4bf4-939b-6df36541b8b7", "25192abd-6043-4c7b-8ced-a4339d7e5f56", "38f079ab-a42e-40aa-b5f3-868898d1de34", "dc530a25-2cc0-4475-a051-d6214e2ba8eb", "8b8d1b6a-7f76-466b-90e6-a16ae68ee9f9", "61c5d146-fcdf-426d-bfc9-47199cab8524", "1db10de4-47e8-4e09-9673-cdae92e1bef0", "66ad281c-f01c-4fc1-8567-ce862e25003c", "aaeb43bc-6f0c-41c2-a6cb-395dd843e10f", "ebfed5d0-b61d-43c3-90a1-f8e1c6b04e42", "fbc0d088-eba8-41a2-8fd9-a8602ded00d9", "c09d6d55-9a1e-4dc0-8851-4e1f269cc3fc", "e7e43395-7990-4142-80b8-dcf895a2bbfe", "0c58bb55-3dd2-47d0-95a2-f7d3b9506520", "238d01c6-3743-413b-a08e-cda027116527", "824ca562-fd48-4ed8-8b0f-8ac15f8466ab", "1b7e121c-8beb-4140-9196-4626e73d5365", "309cea40-21a3-4a5a-b96a-0379e499eafe", "724c04e8-211f-404f-a53d-3e2eb512d990"], "metadata": {}}}}